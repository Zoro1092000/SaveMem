{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "collapsed_sections": [
        "r0VJxZnIDpJT",
        "igYJ4y99D-bU",
        "z_dcpDhREijU",
        "fTEnWpOOEZW9",
        "8rh6Ca1XE6ar",
        "RRCYp7yuLxMe"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zoro1092000/SaveMem/blob/main/Rev_GIN_12Layer_MLP_3Layer_46Channels_2Group_19kParam_3_25GB_f1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Pip & Import."
      ],
      "metadata": {
        "id": "4KD-KUsKDiLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LzKgPv8elRE",
        "outputId": "43137493-7a71-48bd-b3a5-50dc8e25c824"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "H7D6x31EU0fi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e7385c5-0bff-4932-c0da-4d0c997824e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.7/dist-packages (2.1.0.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.7.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (4.64.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.21.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (2.11.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from torch-geometric) (1.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->torch-geometric) (2.0.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torch-geometric) (2022.9.24)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->torch-geometric) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.12.1+cu113.html\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.7/dist-packages (1.6.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: deepdish==0.3.5 in /usr/local/lib/python3.7/dist-packages (0.3.5)\n",
            "Requirement already satisfied: tables in /usr/local/lib/python3.7/dist-packages (from deepdish==0.3.5) (3.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from deepdish==0.3.5) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from deepdish==0.3.5) (1.21.6)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.7/dist-packages (from tables->deepdish==0.3.5) (2.8.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tables->deepdish==0.3.5) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tables->deepdish==0.3.5) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch-optimizer in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from torch-optimizer) (0.1.1)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from torch-optimizer) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->torch-optimizer) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "import torch\n",
        "import sys\n",
        "\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install torch-geometric\n",
        "!pip install torch-cluster -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install deepdish==0.3.5\n",
        "!pip install torch-optimizer\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.nn import Parameter\n",
        "from torch_geometric.nn.inits import glorot, zeros\n",
        "from torch_scatter import scatter_add\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch_optimizer as optimization\n",
        "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout, LayerNorm\n",
        "from torch_geometric.nn import GINConv, GroupAddRev, GATv2Conv\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from itertools import chain\n",
        "import pickle\n",
        "import h5py\n",
        "import deepdish as dd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import inspect\n",
        "import time\n",
        "import math\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def time_since(start):\n",
        "    now = time.time()\n",
        "    s = now - start\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    h = math.floor(m / 60)\n",
        "    m -= h * 60\n",
        "    if h == 0:\n",
        "        if m == 0:\n",
        "            return '%ds' % s\n",
        "        else:\n",
        "            return '%dm %ds' % (m, s)\n",
        "    else:\n",
        "        return '%dh %dm %ds' % (h, m, s)\n"
      ],
      "metadata": {
        "id": "X5j9SrCo4uM5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Data"
      ],
      "metadata": {
        "id": "r0VJxZnIDpJT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data utils\n",
        "def h5group_to_dict(h5group):\n",
        "    group_dict = {k: v[()] for k, v in chain(h5group.items(), h5group.attrs.items())}\n",
        "    return group_dict\n",
        "\n",
        "def sub_dict(full_dict, *keys, to_tensor):\n",
        "    return {k: torch.tensor(full_dict[k]) if to_tensor else full_dict[k] for k in keys if k in full_dict}\n",
        "\n",
        "def build_graph_from_dict_pyg(graph_dict, to_tensor=True):\n",
        "    from torch_geometric.data import Data\n",
        "\n",
        "    g = Data(**sub_dict(graph_dict, 'edge_index', 'x', 'y', 'edge_attr', 'edge_y', to_tensor=to_tensor))\n",
        "    return g\n",
        "\n",
        "# Data loader\n",
        "class GraphDataLoader(DataLoader):\n",
        "    def __init__(self, dataset, batch_size=128, shuffle=False, num_workers=0):\n",
        "\n",
        "        def collate_graph(graph_obj_list):\n",
        "            from torch_geometric.data import Batch\n",
        "            batch = Batch.from_data_list(graph_obj_list)\n",
        "            return batch\n",
        "\n",
        "        super().__init__(\n",
        "            dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "            collate_fn=collate_graph,\n",
        "            num_workers=num_workers)\n",
        "\n",
        "# BotnetDataset\n",
        "class BotnetDataset(Dataset):\n",
        "\n",
        "    def __init__(self, name='chord', root='data/botnet', split='train', graph_format='pyg', split_idx=None, add_nfeat_ones=True,\n",
        "                 in_memory=True):\n",
        "        super().__init__()\n",
        "        assert name in ['chord', 'debru', 'kadem', 'leet', 'c2', 'p2p']\n",
        "        assert split in ['train', 'val', 'test']\n",
        "\n",
        "        if isinstance(root, str):\n",
        "            root = osp.expanduser(osp.normpath(root))\n",
        "\n",
        "        self.name = name\n",
        "        self.root = root\n",
        "        self.split = split\n",
        "        self.split_idx = split_idx\n",
        "        self.add_nfeat_ones = add_nfeat_ones\n",
        "\n",
        "        self._graph_format = graph_format\n",
        "        if split == 'train':\n",
        "            self.path = self.processed_paths[0]\n",
        "            self.num_graphs = 768\n",
        "        elif split == 'val':\n",
        "            self.path = self.processed_paths[1]\n",
        "            self.num_graphs = 96\n",
        "        elif split == 'test':\n",
        "            self.path = self.processed_paths[2]\n",
        "            self.num_graphs = 96\n",
        "\n",
        "        if in_memory:\n",
        "            self.data = dd.io.load(self.path)  # dictionary\n",
        "            self.data_type = 'dict'\n",
        "        else:\n",
        "            # self.data = h5py.File(self.path, 'r')\n",
        "            self.data = None    # defer opening file in each process to make multiprocessing work\n",
        "            self.data_type = 'file'\n",
        "            \n",
        "    @property\n",
        "    def processed_dir(self):\n",
        "        return osp.join(self.root, 'processed')\n",
        "\n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return [self.name + '_' + s + '.hdf5' for s in ('train', 'val', 'test')]\n",
        "\n",
        "    @property\n",
        "    def processed_paths(self):\n",
        "        return [osp.join(self.processed_dir, f) for f in self.processed_file_names]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_graphs\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.data_type == 'dict':\n",
        "            graph_dict = self.data[str(index)]\n",
        "        elif self.data_type == 'file':\n",
        "            if self.data is None:\n",
        "                # only open once in each process\n",
        "                self.data = h5py.File(self.path, 'r')\n",
        "            graph_dict = h5group_to_dict(self.data[str(index)])\n",
        "        else:\n",
        "            raise ValueError\n",
        "\n",
        "        # graph_format == 'pyg':\n",
        "        return build_graph_from_dict_pyg(graph_dict)\n",
        "\n",
        "\n",
        "    def __iter__(self):\n",
        "        for i in range(self.num_graphs):\n",
        "            yield self[i]\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f'{self.__class__.__name__}(topology: {self.name} | split: {self.split} | ' \\\n",
        "               f'#graphs: {len(self)} | graph format: {self.graph_format})'\n"
      ],
      "metadata": {
        "id": "JHHcJ7B-4BmU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III. Measure Performancce"
      ],
      "metadata": {
        "id": "igYJ4y99D-bU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1. Metrics"
      ],
      "metadata": {
        "id": "z_dcpDhREijU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f1(target, pred, label):\n",
        "    # F1 = 2 * (precision * recall) / (precision + recall)\n",
        "    tp = np.sum((target==label) & (pred==label))\n",
        "    fp = np.sum((target!=label) & (pred==label))\n",
        "    fn = np.sum((pred!=label) & (target==label))\n",
        "    \n",
        "    if tp+fp==0 or tp+fn==0:\n",
        "      return np.nan\n",
        "\n",
        "    precision = tp/(tp+fp)\n",
        "    recall = tp/(tp+fn)\n",
        "    \n",
        "    if precision+recall==0:\n",
        "      return np.nan\n",
        "      \n",
        "    f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    return f1\n",
        "\n",
        "def f1_macro(pred, target):\n",
        "    return np.mean([f1(target, pred, label) for label in range(0, 2)])\n",
        "\n",
        "\n",
        "def accuracy(pred, target):\n",
        "    return (pred == target).sum().item() / len(target)\n",
        "\n",
        "\n",
        "def true_positive(pred, target):\n",
        "    return (target[pred == 1] == 1).sum().item()\n",
        "\n",
        "\n",
        "def false_positive(pred, target):\n",
        "    return (target[pred == 1] == 0).sum().item()\n",
        "\n",
        "\n",
        "def true_negative(pred, target):\n",
        "    return (target[pred == 0] == 0).sum().item()\n",
        "\n",
        "\n",
        "def false_negative(pred, target):\n",
        "    return (target[pred == 0] == 1).sum().item()\n",
        "\n",
        "\n",
        "def recall(pred, target):\n",
        "    try:\n",
        "        return true_positive(pred, target) / (target == 1).sum().item()\n",
        "    except:  # divide by zero\n",
        "        return -1\n",
        "\n",
        "\n",
        "def precision(pred, target):\n",
        "    try:\n",
        "        prec = true_positive(pred, target) / (pred == 1).sum().item()\n",
        "        return prec\n",
        "    except:  # divide by zero\n",
        "        return -1\n",
        "\n",
        "\n",
        "def f1_score(pred, target):\n",
        "    prec = precision(pred, target)\n",
        "    rec = recall(pred, target)\n",
        "    try:\n",
        "        return 2 * (prec * rec) / (prec + rec)\n",
        "    except:\n",
        "        return 0\n",
        "\n",
        "\n",
        "def false_positive_rate(pred, target):\n",
        "    try:\n",
        "        return false_positive(pred, target) / (target == 0).sum().item()\n",
        "    except:  # divide by zero\n",
        "        return -1\n",
        "\n",
        "\n",
        "def false_negative_rate(pred, target):\n",
        "    try:\n",
        "        return false_negative(pred, target) / (target == 1).sum().item()\n",
        "    except:  # divide by zero\n",
        "        return -1\n"
      ],
      "metadata": {
        "id": "BN-QIjMREw-7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2. Evaluation"
      ],
      "metadata": {
        "id": "fTEnWpOOEZW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_metrics(target, pred_prob, threshold=0.5):\n",
        "    if isinstance(target, torch.Tensor):\n",
        "        target = target.cpu().numpy()\n",
        "    if isinstance(pred_prob, torch.Tensor):\n",
        "        pred_prob = pred_prob.cpu().numpy()\n",
        "\n",
        "    pred = (pred_prob >= threshold).astype(int)\n",
        "\n",
        "    acc = accuracy(pred, target)\n",
        "    fpr = false_positive_rate(pred, target)\n",
        "    fnr = false_negative_rate(pred, target)\n",
        "    rec = recall(pred, target)\n",
        "    prc = precision(pred, target)\n",
        "    f1 = f1_score(pred, target)\n",
        "    f1macro = f1_macro(pred, target)\n",
        "    result_dict = {'acc': acc, 'fpr': fpr, 'fnr': fnr, 'rec': rec, 'prc': prc, 'f1': f1, 'f1_macro': f1macro}\n",
        "\n",
        "    return result_dict\n",
        "\n",
        "\n",
        "def dict_value_add(dict1, dict2):\n",
        "    result = {key: dict1.get(key, 0) + dict2.get(key, 0)\n",
        "              for key in set(dict1) | set(dict2)}\n",
        "    return result\n",
        "\n",
        "\n",
        "def dict_value_div(dict, n):\n",
        "    result = {key: value / n for key, value in dict.items()}\n",
        "    return result\n",
        "\n",
        "\n",
        "def eval_predictor(dataset, predictor):\n",
        "    result_dict_avg = {}\n",
        "    loss_avg = 0\n",
        "\n",
        "    for data in dataset:\n",
        "        # prediction\n",
        "        try:\n",
        "            pred_prob, loss = predictor(data)\n",
        "            loss_avg += loss\n",
        "        except ValueError:  # if \"too many values to unpack\"\n",
        "            pred_prob = predictor(data)\n",
        "\n",
        "        # get the ground truth target\n",
        "        # graph_format == 'pyg':\n",
        "        target = data.y\n",
        "\n",
        "        # compute the evaluation metrics\n",
        "        result_dict = eval_metrics(target, pred_prob)\n",
        "\n",
        "        result_dict_avg = dict_value_add(result_dict_avg, result_dict)\n",
        "\n",
        "    # average the metrics across all graphs in the dataset as final results\n",
        "    result_dict_avg = dict_value_div(result_dict_avg, len(dataset))\n",
        "    loss_avg = loss_avg / len(dataset)\n",
        "\n",
        "    return result_dict_avg, loss_avg\n",
        "\n",
        "\n",
        "# =================================================================================================================\n",
        "# some examples of the 'predictor' model wrapper to be fed into the above evaluation function (for PyG Data format)\n",
        "# =================================================================================================================\n",
        "class PygRandomPredictor:\n",
        "    def __init__(self):\n",
        "        # torch.manual_seed(0)\n",
        "        pass\n",
        "\n",
        "    def __call__(self, data):\n",
        "        pred_prob = torch.rand(len(data.y))\n",
        "        return pred_prob\n",
        "\n",
        "\n",
        "class PygModelPredictor:\n",
        "    def __init__(self, model, loss_fcn=torch.nn.CrossEntropyLoss()):\n",
        "        self.model = model\n",
        "        self.loss_fcn = loss_fcn\n",
        "        self.device = next(model.parameters()).device\n",
        "\n",
        "    def __call__(self, data):\n",
        "        self.model.eval()\n",
        "        data = data.to(self.device)\n",
        "        with torch.no_grad():\n",
        "            # custom the below line to adjust to your model's input format for forward pass\n",
        "            out = self.model(data.x, data.edge_index)\n",
        "            loss = self.loss_fcn(out, data.y.long())\n",
        "            pred_prob = torch.softmax(out, dim=1)[:, 1]\n",
        "        return pred_prob, loss.float()\n"
      ],
      "metadata": {
        "id": "pqjalkx1EmHc"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IV. Model"
      ],
      "metadata": {
        "id": "5fvRugR_E1QL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GroupAddRev, SAGEConv, GINConv, GCNConv"
      ],
      "metadata": {
        "id": "iOPuMEcyvzPf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNNBlock(torch.nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.norm = LayerNorm(in_channels, elementwise_affine=True)\n",
        "        # self.conv = GCNConv(in_channels, out_channels)\n",
        "        channels = in_channels\n",
        "        self.conv = GINConv(\n",
        "                  Sequential(Linear(channels, channels),\n",
        "                             BatchNorm1d(channels), ReLU(),\n",
        "                             Linear(channels, channels),\n",
        "                             BatchNorm1d(channels), ReLU(),\n",
        "                             Linear(channels, channels), \n",
        "                             BatchNorm1d(channels), ReLU()))\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.norm.reset_parameters()\n",
        "        self.conv.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index, dropout_mask=None):\n",
        "        x = self.norm(x).relu()\n",
        "        if self.training and dropout_mask is not None:\n",
        "            x = x * dropout_mask\n",
        "        return self.conv(x, edge_index)"
      ],
      "metadata": {
        "id": "Vp2D8S_qvwh-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RevGNN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
        "                 dropout, num_groups=2):\n",
        "        super().__init__()\n",
        "\n",
        "        self.dropout = dropout\n",
        "\n",
        "        self.lin1 = Linear(in_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, out_channels)\n",
        "        self.norm = LayerNorm(hidden_channels, elementwise_affine=True)\n",
        "\n",
        "        assert hidden_channels % num_groups == 0\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for _ in range(num_layers):\n",
        "            conv = GNNBlock(\n",
        "                hidden_channels // num_groups,\n",
        "                hidden_channels // num_groups,\n",
        "            )\n",
        "            self.convs.append(GroupAddRev(conv, num_groups=num_groups))\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        self.lin1.reset_parameters()\n",
        "        self.lin2.reset_parameters()\n",
        "        self.norm.reset_parameters()\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.lin1(x)\n",
        "\n",
        "        # Generate a dropout mask which will be shared across GNN blocks:\n",
        "        mask = None\n",
        "        if self.training and self.dropout > 0:\n",
        "            mask = torch.zeros_like(x).bernoulli_(1 - self.dropout)\n",
        "            mask = mask.requires_grad_(False)\n",
        "            mask = mask / (1 - self.dropout)\n",
        "\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, edge_index, mask)\n",
        "        x = self.norm(x).relu()\n",
        "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        return self.lin2(x)"
      ],
      "metadata": {
        "id": "FGkeuO7c9jRd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1. Activation "
      ],
      "metadata": {
        "id": "8rh6Ca1XE6ar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def activation(act, negative_slope=0.2):\n",
        "    activations = nn.ModuleDict([\n",
        "        ['lrelu', nn.LeakyReLU(negative_slope)],\n",
        "        ['relu', nn.ReLU()],\n",
        "        ['elu', nn.ELU()],\n",
        "        ['none', nn.Identity()],\n",
        "    ])\n",
        "    return activations[act]"
      ],
      "metadata": {
        "id": "bzEVz1VwFjKK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# V. Load data"
      ],
      "metadata": {
        "id": "RRCYp7yuLxMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/Shareddrives/botnetdata/P2P'\n",
        "data_name = 'p2p' # 'chord', 'debru', 'kadem', 'leet', 'c2', 'p2p'\n",
        "shuffle = False\n",
        "\n",
        "# ========== load the dataset\n",
        "print('loading dataset...')\n",
        "\n",
        "train_ds = BotnetDataset(name=data_name, root=data_dir, split='train',\n",
        "                         in_memory=True, graph_format='pyg')\n",
        "val_ds = BotnetDataset(name=data_name, root=data_dir, split='val',\n",
        "                       in_memory=True, graph_format='pyg')\n",
        "test_ds = BotnetDataset(name=data_name, root=data_dir, split='test',\n",
        "                        in_memory=False, graph_format='pyg')\n"
      ],
      "metadata": {
        "id": "msBAy6CKLwl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5895329d-072f-4774-cecb-94f3543888fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "8c4GEysKrMho"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "train_loader = GraphDataLoader(train_ds, batch_size=batch_size, shuffle=bool(shuffle), num_workers=0)\n"
      ],
      "metadata": {
        "id": "q23YTuSlmot5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VI. Train"
      ],
      "metadata": {
        "id": "PSY11P9WEX5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============== some default parameters =============\n",
        "devid = 0\n",
        "seed = 0\n",
        "logmode = 'w'\n",
        "log_interval = 96\n",
        "\n",
        "dim_input_feature = 1\n",
        "dim_hidden_feature = 24\n",
        "dim_output_feature = 2\n",
        "act = 'relu' # 'none', 'lrelu', 'relu', 'elu'\n",
        "\n",
        "num_layers = 24\n",
        "num_classes = 2 \n",
        "\n",
        "dropout = 0.2\n",
        "bias = True\n",
        "\n",
        "lr = 0.005 # learning rate\n",
        "weight_decay = 5e-4\n",
        "epochs = 50\n",
        "save_dir = './saved_models'\n",
        "save_name = \"GIN_model.pt\"\n",
        "# ====================================================\n",
        "\n",
        "def train(model, train_loader, val_dataset, test_dataset, optimizer, scheduler=None):\n",
        "    device = next(model.parameters()).device\n",
        "    predictor = PygModelPredictor(model)\n",
        "\n",
        "    best_epoch = 0\n",
        "    max_f1_score = 0\n",
        "    start = time.time()\n",
        "    for ep in range(epochs):\n",
        "        loss_avg_train = 0\n",
        "        num_train_graph = 0\n",
        "        model.train()\n",
        "        for n, batch in enumerate(train_loader):\n",
        "            batch.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            x = model(batch.x, batch.edge_index)\n",
        "            loss = criterion(x, batch.y.long())\n",
        "\n",
        "            loss_avg_train += float(loss)\n",
        "            num_train_graph += batch.num_graphs\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if num_train_graph % log_interval == 0 or n == len(train_loader) - 1:\n",
        "                with torch.no_grad():\n",
        "                    # pred = x.argmax(dim=1)\n",
        "                    pred_prob = torch.softmax(x, dim=1)[:, 1]\n",
        "                    y = batch.y.long()\n",
        "                    result_dict = eval_metrics(y, pred_prob)\n",
        "                print(f'epoch: {ep + 1}, passed number of graphs: {num_train_graph}, '\n",
        "                        f'train running loss: {loss_avg_train / num_train_graph:.5f} (passed time: {time_since(start)})')\n",
        "                print(' ' * 10 + ', '.join(['{}: {:.5f}'.format(k, v) for k, v in result_dict.items()]))\n",
        "\n",
        "        result_dict_avg, loss_avg = eval_predictor(val_dataset, predictor)\n",
        "        print(f'Validation --- epoch: {ep + 1}, loss: {loss_avg:.5f}')\n",
        "        print(' ' * 10 + ', '.join(['{}: {:.5f}'.format(k, v) for k, v in result_dict_avg.items()]))\n",
        "\n",
        "        if scheduler is not None:\n",
        "            scheduler.step(loss_avg)\n",
        "\n",
        "        if result_dict_avg['f1'] > max_f1_score:\n",
        "            save_name = f\"GIN_{ep}: {result_dict_avg['f1']}.pt\"\n",
        "            torch.save(model, os.path.join(save_dir, save_name))\n",
        "            print(f'Better model saved at {os.path.join(save_dir, save_name)}.')\n",
        "            best_epoch = ep\n",
        "            max_f1_score = result_dict_avg['f1']\n",
        "\n",
        "    best_model = torch.load(os.path.join(save_dir, save_name))\n",
        "    print('*' * 12 + f' best model obtained after epoch {best_epoch + 1}, '\n",
        "                       f'saved at {os.path.join(save_dir, save_name)} ' + '*' * 12)\n",
        "    \n",
        "    predictor = PygModelPredictor(best_model)\n",
        "\n",
        "    result_dict_avg, loss_avg = eval_predictor(test_dataset, predictor)\n",
        "    print(f'Testing --- loss: {loss_avg:.5f}')\n",
        "    print(' ' * 10 + ', '.join(['{}: {:.5f}'.format(k, v) for k, v in result_dict_avg.items()]))\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # ========== random seeds and device\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    device = torch.device(f'cuda:{devid}') if devid > -1 else torch.device('cpu')\n",
        "\n",
        "    # ========== logging setup\n",
        "    log_name = os.path.splitext(save_name)[0]\n",
        "    # logger = logging_config(__name__, folder=save_dir, name=log_name, filemode=logmode)\n",
        "    # logger = logging_config(os.path.basename(__file__), folder=save_dir, name=log_name, filemode=logmode)\n",
        "\n",
        "    print('python ' + ' '.join(sys.argv))\n",
        "    print('-' * 30)\n",
        "    #logger.info(args)\n",
        "    print('-' * 30)\n",
        "    print(time.ctime())\n",
        "    print('-' * 30)\n",
        "\n",
        "    # ========== define the model, optimizer, and loss\n",
        "\n",
        "    model = RevGNN(in_channels=dim_input_feature,\n",
        "                   hidden_channels=dim_hidden_feature,\n",
        "                   out_channels=num_classes,\n",
        "                   num_layers=num_layers,  # You can try 1000 layers for fun\n",
        "                   dropout=0.2,\n",
        "                   num_groups=2,\n",
        "    ).to(device)\n",
        "\n",
        "    print('model ' + '-' * 10)\n",
        "    print(repr(model))\n",
        "    model.to(device)\n",
        "    \n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.25, patience=1)\n",
        "\n",
        "    # ========== train the model\n",
        "    print(f\"Batch size: {batch_size}\")\n",
        "    train(model, train_loader, val_ds, test_ds, optimizer, scheduler)\n"
      ],
      "metadata": {
        "id": "3iFDupzCdBl0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f436b0c1-b324-426f-f5b2-bbf981e9fbb4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py -f /root/.local/share/jupyter/runtime/kernel-6b95128e-eb5e-4e83-96ff-47e9c09d3327.json\n",
            "------------------------------\n",
            "------------------------------\n",
            "Tue Nov  8 16:31:21 2022\n",
            "------------------------------\n",
            "model ----------\n",
            "RevGNN(\n",
            "  (lin1): Linear(in_features=1, out_features=24, bias=True)\n",
            "  (lin2): Linear(in_features=24, out_features=2, bias=True)\n",
            "  (norm): LayerNorm((24,), eps=1e-05, elementwise_affine=True)\n",
            "  (convs): ModuleList(\n",
            "    (0): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (1): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (2): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (3): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (4): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (5): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (6): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (7): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (8): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (9): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (10): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (11): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (12): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (13): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (14): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (15): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (16): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (17): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (18): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (19): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (20): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (21): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (22): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "    (23): GroupAddRev(GNNBlock(\n",
            "      (norm): LayerNorm((12,), eps=1e-05, elementwise_affine=True)\n",
            "      (conv): GINConv(nn=Sequential(\n",
            "        (0): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (1): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (4): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU()\n",
            "        (6): Linear(in_features=12, out_features=12, bias=True)\n",
            "        (7): BatchNorm1d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (8): ReLU()\n",
            "      ))\n",
            "    ), num_groups=2)\n",
            "  )\n",
            ")\n",
            "Batch size: 2\n",
            "epoch: 1, passed number of graphs: 96, train running loss: 0.06989 (passed time: 35s)\n",
            "          acc: 0.97827, fpr: 0.00011, fnr: 0.99697, rec: 0.00303, prc: 0.38776, f1: 0.00601, f1_macro: 0.49751\n",
            "epoch: 1, passed number of graphs: 192, train running loss: 0.04899 (passed time: 1m 8s)\n",
            "          acc: 0.98105, fpr: 0.00010, fnr: 0.88241, rec: 0.11759, prc: 0.96386, f1: 0.20961, f1_macro: 0.60001\n",
            "epoch: 1, passed number of graphs: 288, train running loss: 0.03710 (passed time: 1m 40s)\n",
            "          acc: 0.99832, fpr: 0.00010, fnr: 0.07467, rec: 0.92533, prc: 0.99491, f1: 0.95886, f1_macro: 0.97900\n",
            "epoch: 1, passed number of graphs: 384, train running loss: 0.03073 (passed time: 2m 13s)\n",
            "          acc: 0.99543, fpr: 0.00000, fnr: 0.20735, rec: 0.79265, prc: 1.00000, f1: 0.88434, f1_macro: 0.94100\n",
            "epoch: 1, passed number of graphs: 480, train running loss: 0.02626 (passed time: 2m 45s)\n",
            "          acc: 0.99207, fpr: 0.00212, fnr: 0.27050, rec: 0.72950, prc: 0.88383, f1: 0.79928, f1_macro: 0.89762\n",
            "epoch: 1, passed number of graphs: 576, train running loss: 0.02269 (passed time: 3m 18s)\n",
            "          acc: 0.99931, fpr: 0.00000, fnr: 0.03212, rec: 0.96788, prc: 0.99983, f1: 0.98360, f1_macro: 0.99162\n",
            "epoch: 1, passed number of graphs: 672, train running loss: 0.02000 (passed time: 3m 50s)\n",
            "          acc: 0.99057, fpr: 0.00028, fnr: 0.42314, rec: 0.57686, prc: 0.97858, f1: 0.72585, f1_macro: 0.86052\n",
            "epoch: 1, passed number of graphs: 768, train running loss: 0.01877 (passed time: 4m 23s)\n",
            "          acc: 0.99921, fpr: 0.00000, fnr: 0.03687, rec: 0.96313, prc: 0.99983, f1: 0.98114, f1_macro: 0.99037\n",
            "Validation --- epoch: 1, loss: 0.00386\n",
            "          acc: 0.99930, prc: 0.99608, fpr: 0.00008, f1_macro: 0.99133, fnr: 0.02863, f1: 0.98302, rec: 0.97137\n",
            "Better model saved at ./saved_models/GIN_0: 0.9830189617909625.pt.\n",
            "epoch: 2, passed number of graphs: 96, train running loss: 0.00340 (passed time: 5m 5s)\n",
            "          acc: 0.99939, fpr: 0.00000, fnr: 0.02807, rec: 0.97193, prc: 0.99984, f1: 0.98568, f1_macro: 0.99269\n",
            "epoch: 2, passed number of graphs: 192, train running loss: 0.00387 (passed time: 5m 37s)\n",
            "          acc: 0.99931, fpr: 0.00000, fnr: 0.03250, rec: 0.96750, prc: 1.00000, f1: 0.98348, f1_macro: 0.99156\n",
            "epoch: 2, passed number of graphs: 288, train running loss: 0.00357 (passed time: 6m 10s)\n",
            "          acc: 0.99920, fpr: 0.00000, fnr: 0.03775, rec: 0.96225, prc: 1.00000, f1: 0.98076, f1_macro: 0.99018\n",
            "epoch: 2, passed number of graphs: 384, train running loss: 0.00340 (passed time: 6m 42s)\n",
            "          acc: 0.99941, fpr: 0.00000, fnr: 0.02658, rec: 0.97342, prc: 0.99983, f1: 0.98645, f1_macro: 0.99307\n",
            "epoch: 2, passed number of graphs: 480, train running loss: 0.00318 (passed time: 7m 15s)\n",
            "          acc: 0.99948, fpr: 0.00004, fnr: 0.02254, rec: 0.97746, prc: 0.99833, f1: 0.98778, f1_macro: 0.99376\n",
            "epoch: 2, passed number of graphs: 576, train running loss: 0.00317 (passed time: 7m 48s)\n",
            "          acc: 0.99937, fpr: 0.00001, fnr: 0.02889, rec: 0.97111, prc: 0.99934, f1: 0.98502, f1_macro: 0.99235\n",
            "epoch: 2, passed number of graphs: 672, train running loss: 0.00317 (passed time: 8m 20s)\n",
            "          acc: 0.99142, fpr: 0.00822, fnr: 0.02477, rec: 0.97523, prc: 0.72422, f1: 0.83119, f1_macro: 0.91339\n",
            "epoch: 2, passed number of graphs: 768, train running loss: 0.00615 (passed time: 8m 53s)\n",
            "          acc: 0.99562, fpr: 0.00000, fnr: 0.20587, rec: 0.79413, prc: 0.99979, f1: 0.88517, f1_macro: 0.94147\n",
            "Validation --- epoch: 2, loss: 0.00568\n",
            "          acc: 0.99940, prc: 0.99937, fpr: 0.00001, f1_macro: 0.99246, fnr: 0.02711, f1: 0.98523, rec: 0.97289\n",
            "Better model saved at ./saved_models/GIN_1: 0.9852316798163029.pt.\n",
            "epoch: 3, passed number of graphs: 96, train running loss: 0.01894 (passed time: 9m 35s)\n",
            "          acc: 0.99739, fpr: 0.00191, fnr: 0.03430, rec: 0.96570, prc: 0.91811, f1: 0.94130, f1_macro: 0.96998\n",
            "epoch: 3, passed number of graphs: 192, train running loss: 0.02071 (passed time: 10m 8s)\n",
            "          acc: 0.97863, fpr: 0.00000, fnr: 1.00000, rec: 0.00000, prc: -1.00000, f1: 0.00000, f1_macro: nan\n",
            "epoch: 3, passed number of graphs: 288, train running loss: 0.03112 (passed time: 10m 40s)\n",
            "          acc: 0.97892, fpr: 0.00004, fnr: 0.99281, rec: 0.00719, prc: 0.80000, f1: 0.01425, f1_macro: 0.50180\n",
            "epoch: 3, passed number of graphs: 384, train running loss: 0.03482 (passed time: 11m 13s)\n",
            "          acc: 0.97768, fpr: 0.00055, fnr: 0.98921, rec: 0.01079, prc: 0.30594, f1: 0.02085, f1_macro: 0.50478\n",
            "epoch: 3, passed number of graphs: 480, train running loss: 0.03689 (passed time: 11m 45s)\n",
            "          acc: 0.97837, fpr: 0.00000, fnr: 1.00000, rec: 0.00000, prc: -1.00000, f1: 0.00000, f1_macro: nan\n",
            "epoch: 3, passed number of graphs: 576, train running loss: 0.03535 (passed time: 12m 18s)\n",
            "          acc: 0.99019, fpr: 0.00000, fnr: 0.45811, rec: 0.54189, prc: 0.99970, f1: 0.70282, f1_macro: 0.84891\n",
            "epoch: 3, passed number of graphs: 672, train running loss: 0.03352 (passed time: 12m 51s)\n",
            "          acc: 0.99470, fpr: 0.00036, fnr: 0.22851, rec: 0.77149, prc: 0.97931, f1: 0.86307, f1_macro: 0.93018\n",
            "epoch: 3, passed number of graphs: 768, train running loss: 0.03049 (passed time: 13m 23s)\n",
            "          acc: 0.99640, fpr: 0.00000, fnr: 0.16949, rec: 0.83051, prc: 0.99980, f1: 0.90732, f1_macro: 0.95274\n",
            "Validation --- epoch: 3, loss: 0.51946\n",
            "          acc: 0.98946, prc: 0.70788, fpr: 0.01067, f1_macro: 0.90546, fnr: 0.00447, f1: 0.81635, rec: 0.99553\n",
            "epoch: 4, passed number of graphs: 96, train running loss: 0.00514 (passed time: 14m 5s)\n",
            "          acc: 0.99907, fpr: 0.00006, fnr: 0.04020, rec: 0.95980, prc: 0.99735, f1: 0.97821, f1_macro: 0.98887\n",
            "epoch: 4, passed number of graphs: 192, train running loss: 0.00444 (passed time: 14m 38s)\n",
            "          acc: 0.99963, fpr: 0.00000, fnr: 0.01715, rec: 0.98285, prc: 1.00000, f1: 0.99135, f1_macro: 0.99558\n",
            "epoch: 4, passed number of graphs: 288, train running loss: 0.00436 (passed time: 15m 10s)\n",
            "          acc: 0.99959, fpr: 0.00006, fnr: 0.01634, rec: 0.98366, prc: 0.99718, f1: 0.99038, f1_macro: 0.99508\n",
            "epoch: 4, passed number of graphs: 384, train running loss: 0.00403 (passed time: 15m 43s)\n",
            "          acc: 0.99968, fpr: 0.00001, fnr: 0.01402, rec: 0.98598, prc: 0.99951, f1: 0.99270, f1_macro: 0.99627\n",
            "epoch: 4, passed number of graphs: 480, train running loss: 0.00353 (passed time: 16m 15s)\n",
            "          acc: 0.99971, fpr: 0.00001, fnr: 0.01258, rec: 0.98742, prc: 0.99934, f1: 0.99334, f1_macro: 0.99660\n",
            "epoch: 4, passed number of graphs: 576, train running loss: 0.00320 (passed time: 16m 48s)\n",
            "          acc: 0.99958, fpr: 0.00004, fnr: 0.01792, rec: 0.98208, prc: 0.99820, f1: 0.99007, f1_macro: 0.99493\n",
            "epoch: 4, passed number of graphs: 672, train running loss: 0.00307 (passed time: 17m 21s)\n",
            "          acc: 0.99950, fpr: 0.00031, fnr: 0.00895, rec: 0.99105, prc: 0.98585, f1: 0.98845, f1_macro: 0.99409\n",
            "epoch: 4, passed number of graphs: 768, train running loss: 0.00300 (passed time: 17m 53s)\n",
            "          acc: 0.99953, fpr: 0.00001, fnr: 0.02170, rec: 0.97830, prc: 0.99967, f1: 0.98887, f1_macro: 0.99432\n",
            "Validation --- epoch: 4, loss: 0.00160\n",
            "          acc: 0.99976, prc: 0.99811, fpr: 0.00004, f1_macro: 0.99686, fnr: 0.00933, f1: 0.99384, rec: 0.99067\n",
            "Better model saved at ./saved_models/GIN_3: 0.9938360164396545.pt.\n",
            "epoch: 5, passed number of graphs: 96, train running loss: 0.00147 (passed time: 18m 35s)\n",
            "          acc: 0.99935, fpr: 0.00001, fnr: 0.02967, rec: 0.97033, prc: 0.99967, f1: 0.98478, f1_macro: 0.99222\n",
            "epoch: 5, passed number of graphs: 192, train running loss: 0.00179 (passed time: 19m 8s)\n",
            "          acc: 0.99974, fpr: 0.00000, fnr: 0.01209, rec: 0.98791, prc: 0.99983, f1: 0.99384, f1_macro: 0.99685\n",
            "epoch: 5, passed number of graphs: 288, train running loss: 0.00184 (passed time: 19m 40s)\n",
            "          acc: 0.99975, fpr: 0.00005, fnr: 0.00948, rec: 0.99052, prc: 0.99786, f1: 0.99418, f1_macro: 0.99703\n",
            "epoch: 5, passed number of graphs: 384, train running loss: 0.00174 (passed time: 20m 13s)\n",
            "          acc: 0.99961, fpr: 0.00001, fnr: 0.01708, rec: 0.98292, prc: 0.99951, f1: 0.99115, f1_macro: 0.99547\n",
            "epoch: 5, passed number of graphs: 480, train running loss: 0.00164 (passed time: 20m 46s)\n",
            "          acc: 0.99972, fpr: 0.00002, fnr: 0.01209, rec: 0.98791, prc: 0.99901, f1: 0.99343, f1_macro: 0.99664\n",
            "epoch: 5, passed number of graphs: 576, train running loss: 0.00166 (passed time: 21m 18s)\n",
            "          acc: 0.99965, fpr: 0.00011, fnr: 0.01130, rec: 0.98870, prc: 0.99496, f1: 0.99182, f1_macro: 0.99582\n",
            "epoch: 5, passed number of graphs: 672, train running loss: 0.00171 (passed time: 21m 51s)\n",
            "          acc: 0.99948, fpr: 0.00029, fnr: 0.01087, rec: 0.98913, prc: 0.98677, f1: 0.98795, f1_macro: 0.99384\n",
            "epoch: 5, passed number of graphs: 768, train running loss: 0.00178 (passed time: 22m 23s)\n",
            "          acc: 0.99968, fpr: 0.00000, fnr: 0.01501, rec: 0.98499, prc: 0.99983, f1: 0.99236, f1_macro: 0.99610\n",
            "Validation --- epoch: 5, loss: 0.00167\n",
            "          acc: 0.99972, prc: 0.99738, fpr: 0.00006, f1_macro: 0.99647, fnr: 0.01004, f1: 0.99309, rec: 0.98996\n",
            "epoch: 6, passed number of graphs: 96, train running loss: 0.00112 (passed time: 23m 5s)\n",
            "          acc: 0.99973, fpr: 0.00000, fnr: 0.01228, rec: 0.98772, prc: 0.99984, f1: 0.99374, f1_macro: 0.99680\n",
            "epoch: 6, passed number of graphs: 192, train running loss: 0.00161 (passed time: 23m 38s)\n",
            "          acc: 0.99976, fpr: 0.00000, fnr: 0.01111, rec: 0.98889, prc: 1.00000, f1: 0.99442, f1_macro: 0.99715\n",
            "epoch: 6, passed number of graphs: 288, train running loss: 0.00148 (passed time: 24m 10s)\n",
            "          acc: 0.99960, fpr: 0.00004, fnr: 0.01699, rec: 0.98301, prc: 0.99801, f1: 0.99045, f1_macro: 0.99512\n",
            "epoch: 6, passed number of graphs: 384, train running loss: 0.00144 (passed time: 24m 43s)\n",
            "          acc: 0.99977, fpr: 0.00001, fnr: 0.00967, rec: 0.99033, prc: 0.99935, f1: 0.99482, f1_macro: 0.99735\n",
            "epoch: 6, passed number of graphs: 480, train running loss: 0.00141 (passed time: 25m 16s)\n",
            "          acc: 0.99978, fpr: 0.00004, fnr: 0.00833, rec: 0.99167, prc: 0.99836, f1: 0.99500, f1_macro: 0.99745\n",
            "epoch: 6, passed number of graphs: 576, train running loss: 0.00159 (passed time: 25m 48s)\n",
            "          acc: 0.99943, fpr: 0.00016, fnr: 0.01969, rec: 0.98031, prc: 0.99281, f1: 0.98652, f1_macro: 0.99311\n",
            "epoch: 6, passed number of graphs: 672, train running loss: 0.00170 (passed time: 26m 21s)\n",
            "          acc: 0.99927, fpr: 0.00022, fnr: 0.02349, rec: 0.97651, prc: 0.98980, f1: 0.98311, f1_macro: 0.99137\n",
            "epoch: 6, passed number of graphs: 768, train running loss: 0.00169 (passed time: 26m 54s)\n",
            "          acc: 0.99953, fpr: 0.00000, fnr: 0.02186, rec: 0.97814, prc: 0.99983, f1: 0.98887, f1_macro: 0.99431\n",
            "Validation --- epoch: 6, loss: 0.00158\n",
            "          acc: 0.99975, prc: 0.99762, fpr: 0.00005, f1_macro: 0.99676, fnr: 0.00918, f1: 0.99366, rec: 0.99082\n",
            "epoch: 7, passed number of graphs: 96, train running loss: 0.00154 (passed time: 27m 36s)\n",
            "          acc: 0.99976, fpr: 0.00001, fnr: 0.01085, rec: 0.98915, prc: 0.99968, f1: 0.99439, f1_macro: 0.99713\n",
            "epoch: 7, passed number of graphs: 192, train running loss: 0.00172 (passed time: 28m 9s)\n",
            "          acc: 0.99977, fpr: 0.00000, fnr: 0.01045, rec: 0.98955, prc: 0.99983, f1: 0.99466, f1_macro: 0.99727\n",
            "epoch: 7, passed number of graphs: 288, train running loss: 0.00150 (passed time: 28m 41s)\n",
            "          acc: 0.99974, fpr: 0.00004, fnr: 0.01046, rec: 0.98954, prc: 0.99835, f1: 0.99393, f1_macro: 0.99690\n",
            "epoch: 7, passed number of graphs: 384, train running loss: 0.00154 (passed time: 29m 14s)\n",
            "          acc: 0.99681, fpr: 0.00001, fnr: 0.14468, rec: 0.85532, prc: 0.99962, f1: 0.92186, f1_macro: 0.96012\n",
            "epoch: 7, passed number of graphs: 480, train running loss: 0.00150 (passed time: 29m 47s)\n",
            "          acc: 0.99980, fpr: 0.00003, fnr: 0.00800, rec: 0.99200, prc: 0.99852, f1: 0.99525, f1_macro: 0.99757\n",
            "epoch: 7, passed number of graphs: 576, train running loss: 0.00143 (passed time: 30m 20s)\n",
            "          acc: 0.99969, fpr: 0.00015, fnr: 0.00743, rec: 0.99257, prc: 0.99306, f1: 0.99282, f1_macro: 0.99633\n",
            "epoch: 7, passed number of graphs: 672, train running loss: 0.00148 (passed time: 30m 52s)\n",
            "          acc: 0.99952, fpr: 0.00029, fnr: 0.00911, rec: 0.99089, prc: 0.98679, f1: 0.98884, f1_macro: 0.99429\n",
            "epoch: 7, passed number of graphs: 768, train running loss: 0.00159 (passed time: 31m 25s)\n",
            "          acc: 0.99979, fpr: 0.00001, fnr: 0.00946, rec: 0.99054, prc: 0.99951, f1: 0.99500, f1_macro: 0.99745\n",
            "Validation --- epoch: 7, loss: 0.00255\n",
            "          acc: 0.99950, prc: 0.98907, fpr: 0.00024, f1_macro: 0.99371, fnr: 0.01212, f1: 0.98768, rec: 0.98788\n",
            "epoch: 8, passed number of graphs: 96, train running loss: 0.00141 (passed time: 32m 7s)\n",
            "          acc: 0.99983, fpr: 0.00001, fnr: 0.00734, rec: 0.99266, prc: 0.99968, f1: 0.99616, f1_macro: 0.99804\n",
            "epoch: 8, passed number of graphs: 192, train running loss: 0.00155 (passed time: 32m 39s)\n",
            "          acc: 0.99971, fpr: 0.00000, fnr: 0.01339, rec: 0.98661, prc: 1.00000, f1: 0.99326, f1_macro: 0.99656\n",
            "epoch: 8, passed number of graphs: 288, train running loss: 0.00147 (passed time: 33m 12s)\n",
            "          acc: 0.99976, fpr: 0.00003, fnr: 0.00964, rec: 0.99036, prc: 0.99852, f1: 0.99442, f1_macro: 0.99715\n",
            "epoch: 8, passed number of graphs: 384, train running loss: 0.00149 (passed time: 33m 45s)\n",
            "          acc: 0.99979, fpr: 0.00001, fnr: 0.00886, rec: 0.99114, prc: 0.99935, f1: 0.99523, f1_macro: 0.99756\n",
            "epoch: 8, passed number of graphs: 480, train running loss: 0.00142 (passed time: 34m 17s)\n",
            "          acc: 0.99978, fpr: 0.00005, fnr: 0.00817, rec: 0.99183, prc: 0.99786, f1: 0.99484, f1_macro: 0.99736\n",
            "epoch: 8, passed number of graphs: 576, train running loss: 0.00146 (passed time: 34m 50s)\n",
            "          acc: 0.99976, fpr: 0.00009, fnr: 0.00726, rec: 0.99274, prc: 0.99595, f1: 0.99434, f1_macro: 0.99711\n",
            "epoch: 8, passed number of graphs: 672, train running loss: 0.00152 (passed time: 35m 23s)\n",
            "          acc: 0.99942, fpr: 0.00027, fnr: 0.01454, rec: 0.98546, prc: 0.98767, f1: 0.98656, f1_macro: 0.99313\n",
            "epoch: 8, passed number of graphs: 768, train running loss: 0.00157 (passed time: 35m 55s)\n",
            "          acc: 0.99975, fpr: 0.00000, fnr: 0.01175, rec: 0.98825, prc: 0.99983, f1: 0.99401, f1_macro: 0.99694\n",
            "Validation --- epoch: 8, loss: 0.00156\n",
            "          acc: 0.99974, prc: 0.99807, fpr: 0.00004, f1_macro: 0.99660, fnr: 0.01029, f1: 0.99333, rec: 0.98971\n",
            "epoch: 9, passed number of graphs: 96, train running loss: 0.00123 (passed time: 36m 37s)\n",
            "          acc: 0.99984, fpr: 0.00000, fnr: 0.00734, rec: 0.99266, prc: 0.99984, f1: 0.99624, f1_macro: 0.99808\n",
            "epoch: 9, passed number of graphs: 192, train running loss: 0.00162 (passed time: 37m 9s)\n",
            "          acc: 0.99968, fpr: 0.00000, fnr: 0.01486, rec: 0.98514, prc: 1.00000, f1: 0.99251, f1_macro: 0.99618\n",
            "epoch: 9, passed number of graphs: 288, train running loss: 0.00151 (passed time: 37m 42s)\n",
            "          acc: 0.99973, fpr: 0.00002, fnr: 0.01176, rec: 0.98824, prc: 0.99917, f1: 0.99367, f1_macro: 0.99677\n",
            "epoch: 9, passed number of graphs: 384, train running loss: 0.00216 (passed time: 38m 15s)\n",
            "          acc: 0.99885, fpr: 0.00001, fnr: 0.05172, rec: 0.94828, prc: 0.99966, f1: 0.97329, f1_macro: 0.98635\n",
            "epoch: 9, passed number of graphs: 480, train running loss: 0.00301 (passed time: 38m 47s)\n",
            "          acc: 0.99941, fpr: 0.00000, fnr: 0.02728, rec: 0.97272, prc: 0.99983, f1: 0.98609, f1_macro: 0.99289\n",
            "epoch: 9, passed number of graphs: 576, train running loss: 0.00295 (passed time: 39m 20s)\n",
            "          acc: 0.99970, fpr: 0.00002, fnr: 0.01324, rec: 0.98676, prc: 0.99902, f1: 0.99285, f1_macro: 0.99635\n",
            "epoch: 9, passed number of graphs: 672, train running loss: 0.00289 (passed time: 39m 52s)\n",
            "          acc: 0.99490, fpr: 0.00040, fnr: 0.21716, rec: 0.78284, prc: 0.97726, f1: 0.86931, f1_macro: 0.93336\n",
            "epoch: 9, passed number of graphs: 768, train running loss: 0.00272 (passed time: 40m 25s)\n",
            "          acc: 0.99966, fpr: 0.00000, fnr: 0.01582, rec: 0.98418, prc: 0.99983, f1: 0.99194, f1_macro: 0.99588\n",
            "Validation --- epoch: 9, loss: 0.00193\n",
            "          acc: 0.99968, prc: 0.99595, fpr: 0.00010, f1_macro: 0.99604, fnr: 0.01015, f1: 0.99223, rec: 0.98985\n",
            "epoch: 10, passed number of graphs: 96, train running loss: 0.00118 (passed time: 41m 6s)\n",
            "          acc: 0.99983, fpr: 0.00000, fnr: 0.00750, rec: 0.99250, prc: 0.99984, f1: 0.99616, f1_macro: 0.99804\n",
            "epoch: 10, passed number of graphs: 192, train running loss: 0.00120 (passed time: 41m 39s)\n",
            "          acc: 0.99976, fpr: 0.00000, fnr: 0.01127, rec: 0.98873, prc: 1.00000, f1: 0.99433, f1_macro: 0.99711\n",
            "epoch: 10, passed number of graphs: 288, train running loss: 0.00112 (passed time: 42m 11s)\n",
            "          acc: 0.99979, fpr: 0.00000, fnr: 0.00980, rec: 0.99020, prc: 0.99984, f1: 0.99499, f1_macro: 0.99744\n",
            "epoch: 10, passed number of graphs: 384, train running loss: 0.00105 (passed time: 42m 44s)\n",
            "          acc: 0.99974, fpr: 0.00000, fnr: 0.01176, rec: 0.98824, prc: 0.99984, f1: 0.99400, f1_macro: 0.99694\n",
            "epoch: 10, passed number of graphs: 480, train running loss: 0.00102 (passed time: 43m 17s)\n",
            "          acc: 0.99978, fpr: 0.00001, fnr: 0.00996, rec: 0.99004, prc: 0.99967, f1: 0.99483, f1_macro: 0.99736\n",
            "epoch: 10, passed number of graphs: 576, train running loss: 0.00104 (passed time: 43m 49s)\n",
            "          acc: 0.99979, fpr: 0.00006, fnr: 0.00694, rec: 0.99306, prc: 0.99708, f1: 0.99507, f1_macro: 0.99748\n",
            "epoch: 10, passed number of graphs: 672, train running loss: 0.00113 (passed time: 44m 22s)\n",
            "          acc: 0.99507, fpr: 0.00039, fnr: 0.20997, rec: 0.79003, prc: 0.97824, f1: 0.87412, f1_macro: 0.93580\n",
            "epoch: 10, passed number of graphs: 768, train running loss: 0.00125 (passed time: 44m 54s)\n",
            "          acc: 0.99980, fpr: 0.00000, fnr: 0.00946, rec: 0.99054, prc: 0.99984, f1: 0.99517, f1_macro: 0.99753\n",
            "Validation --- epoch: 10, loss: 0.00199\n",
            "          acc: 0.99964, prc: 0.99676, fpr: 0.00008, f1_macro: 0.99545, fnr: 0.01331, f1: 0.99109, rec: 0.98669\n",
            "epoch: 11, passed number of graphs: 96, train running loss: 0.00208 (passed time: 45m 36s)\n",
            "          acc: 0.99982, fpr: 0.00001, fnr: 0.00782, rec: 0.99218, prc: 0.99952, f1: 0.99584, f1_macro: 0.99787\n",
            "epoch: 11, passed number of graphs: 192, train running loss: 0.00167 (passed time: 46m 9s)\n",
            "          acc: 0.99977, fpr: 0.00000, fnr: 0.01062, rec: 0.98938, prc: 1.00000, f1: 0.99466, f1_macro: 0.99727\n",
            "epoch: 11, passed number of graphs: 288, train running loss: 0.00177 (passed time: 46m 41s)\n",
            "          acc: 0.99980, fpr: 0.00001, fnr: 0.00915, rec: 0.99085, prc: 0.99951, f1: 0.99516, f1_macro: 0.99753\n",
            "epoch: 11, passed number of graphs: 384, train running loss: 0.00182 (passed time: 47m 14s)\n",
            "          acc: 0.99975, fpr: 0.00001, fnr: 0.01096, rec: 0.98904, prc: 0.99951, f1: 0.99425, f1_macro: 0.99706\n",
            "epoch: 11, passed number of graphs: 480, train running loss: 0.00169 (passed time: 47m 46s)\n",
            "          acc: 0.99703, fpr: 0.00002, fnr: 0.13639, rec: 0.86361, prc: 0.99887, f1: 0.92633, f1_macro: 0.96240\n",
            "epoch: 11, passed number of graphs: 576, train running loss: 0.00163 (passed time: 48m 19s)\n",
            "          acc: 0.99549, fpr: 0.00011, fnr: 0.20533, rec: 0.79467, prc: 0.99354, f1: 0.88305, f1_macro: 0.94038\n",
            "epoch: 11, passed number of graphs: 672, train running loss: 0.00161 (passed time: 48m 52s)\n",
            "          acc: 0.99946, fpr: 0.00035, fnr: 0.00911, rec: 0.99089, prc: 0.98444, f1: 0.98766, f1_macro: 0.99369\n",
            "epoch: 11, passed number of graphs: 768, train running loss: 0.00158 (passed time: 49m 24s)\n",
            "          acc: 0.99975, fpr: 0.00000, fnr: 0.01158, rec: 0.98842, prc: 0.99983, f1: 0.99409, f1_macro: 0.99698\n",
            "Validation --- epoch: 11, loss: 0.00164\n",
            "          acc: 0.99973, prc: 0.99811, fpr: 0.00004, f1_macro: 0.99654, fnr: 0.01053, f1: 0.99322, rec: 0.98947\n",
            "epoch: 12, passed number of graphs: 96, train running loss: 0.00145 (passed time: 50m 6s)\n",
            "          acc: 0.99982, fpr: 0.00000, fnr: 0.00798, rec: 0.99202, prc: 0.99984, f1: 0.99592, f1_macro: 0.99791\n",
            "epoch: 12, passed number of graphs: 192, train running loss: 0.00146 (passed time: 50m 38s)\n",
            "          acc: 0.99980, fpr: 0.00000, fnr: 0.00931, rec: 0.99069, prc: 1.00000, f1: 0.99532, f1_macro: 0.99761\n",
            "epoch: 12, passed number of graphs: 288, train running loss: 0.00147 (passed time: 51m 11s)\n",
            "          acc: 0.99981, fpr: 0.00001, fnr: 0.00866, rec: 0.99134, prc: 0.99951, f1: 0.99541, f1_macro: 0.99765\n",
            "epoch: 12, passed number of graphs: 384, train running loss: 0.00136 (passed time: 51m 44s)\n",
            "          acc: 0.99974, fpr: 0.00001, fnr: 0.01128, rec: 0.98872, prc: 0.99951, f1: 0.99409, f1_macro: 0.99698\n",
            "epoch: 12, passed number of graphs: 480, train running loss: 0.00141 (passed time: 52m 16s)\n",
            "          acc: 0.99982, fpr: 0.00001, fnr: 0.00768, rec: 0.99232, prc: 0.99934, f1: 0.99582, f1_macro: 0.99786\n",
            "epoch: 12, passed number of graphs: 576, train running loss: 0.00135 (passed time: 52m 49s)\n",
            "          acc: 0.99982, fpr: 0.00005, fnr: 0.00613, rec: 0.99387, prc: 0.99757, f1: 0.99571, f1_macro: 0.99781\n",
            "epoch: 12, passed number of graphs: 672, train running loss: 0.00135 (passed time: 53m 22s)\n",
            "          acc: 0.99946, fpr: 0.00032, fnr: 0.01039, rec: 0.98961, prc: 0.98552, f1: 0.98756, f1_macro: 0.99364\n",
            "epoch: 12, passed number of graphs: 768, train running loss: 0.00135 (passed time: 53m 54s)\n",
            "          acc: 0.99974, fpr: 0.00005, fnr: 0.00995, rec: 0.99005, prc: 0.99786, f1: 0.99394, f1_macro: 0.99690\n",
            "Validation --- epoch: 12, loss: 0.00161\n",
            "          acc: 0.99972, prc: 0.99727, fpr: 0.00006, f1_macro: 0.99646, fnr: 0.00993, f1: 0.99307, rec: 0.99007\n",
            "epoch: 13, passed number of graphs: 96, train running loss: 0.00115 (passed time: 54m 36s)\n",
            "          acc: 0.99967, fpr: 0.00001, fnr: 0.01483, rec: 0.98517, prc: 0.99951, f1: 0.99229, f1_macro: 0.99606\n",
            "epoch: 13, passed number of graphs: 192, train running loss: 0.00115 (passed time: 55m 9s)\n",
            "          acc: 0.99981, fpr: 0.00000, fnr: 0.00898, rec: 0.99102, prc: 1.00000, f1: 0.99549, f1_macro: 0.99770\n",
            "epoch: 13, passed number of graphs: 288, train running loss: 0.00106 (passed time: 55m 42s)\n",
            "          acc: 0.99977, fpr: 0.00001, fnr: 0.01046, rec: 0.98954, prc: 0.99967, f1: 0.99458, f1_macro: 0.99723\n",
            "epoch: 13, passed number of graphs: 384, train running loss: 0.00101 (passed time: 56m 15s)\n",
            "          acc: 0.99980, fpr: 0.00001, fnr: 0.00886, rec: 0.99114, prc: 0.99968, f1: 0.99539, f1_macro: 0.99764\n",
            "epoch: 13, passed number of graphs: 480, train running loss: 0.00103 (passed time: 56m 47s)\n",
            "          acc: 0.99983, fpr: 0.00003, fnr: 0.00653, rec: 0.99347, prc: 0.99885, f1: 0.99615, f1_macro: 0.99803\n",
            "epoch: 13, passed number of graphs: 576, train running loss: 0.00102 (passed time: 57m 20s)\n",
            "          acc: 0.99982, fpr: 0.00005, fnr: 0.00630, rec: 0.99370, prc: 0.99773, f1: 0.99571, f1_macro: 0.99781\n",
            "epoch: 13, passed number of graphs: 672, train running loss: 0.00103 (passed time: 57m 52s)\n",
            "          acc: 0.99948, fpr: 0.00036, fnr: 0.00767, rec: 0.99233, prc: 0.98400, f1: 0.98815, f1_macro: 0.99394\n",
            "epoch: 13, passed number of graphs: 768, train running loss: 0.00102 (passed time: 58m 25s)\n",
            "          acc: 0.99979, fpr: 0.00000, fnr: 0.00962, rec: 0.99038, prc: 0.99984, f1: 0.99508, f1_macro: 0.99749\n",
            "Validation --- epoch: 13, loss: 0.00169\n",
            "          acc: 0.99971, prc: 0.99572, fpr: 0.00010, f1_macro: 0.99632, fnr: 0.00884, f1: 0.99279, rec: 0.99116\n",
            "epoch: 14, passed number of graphs: 96, train running loss: 0.00138 (passed time: 59m 7s)\n",
            "          acc: 0.99984, fpr: 0.00001, fnr: 0.00702, rec: 0.99298, prc: 0.99968, f1: 0.99632, f1_macro: 0.99812\n",
            "epoch: 14, passed number of graphs: 192, train running loss: 0.00126 (passed time: 59m 39s)\n",
            "          acc: 0.99982, fpr: 0.00000, fnr: 0.00833, rec: 0.99167, prc: 1.00000, f1: 0.99582, f1_macro: 0.99786\n",
            "epoch: 14, passed number of graphs: 288, train running loss: 0.00124 (passed time: 1h 0m 12s)\n",
            "          acc: 0.99982, fpr: 0.00003, fnr: 0.00719, rec: 0.99281, prc: 0.99852, f1: 0.99566, f1_macro: 0.99778\n",
            "epoch: 14, passed number of graphs: 384, train running loss: 0.00125 (passed time: 1h 0m 45s)\n",
            "          acc: 0.99978, fpr: 0.00001, fnr: 0.00934, rec: 0.99066, prc: 0.99951, f1: 0.99506, f1_macro: 0.99748\n",
            "epoch: 14, passed number of graphs: 480, train running loss: 0.00117 (passed time: 1h 1m 17s)\n",
            "          acc: 0.99980, fpr: 0.00002, fnr: 0.00833, rec: 0.99167, prc: 0.99918, f1: 0.99541, f1_macro: 0.99765\n",
            "epoch: 14, passed number of graphs: 576, train running loss: 0.00118 (passed time: 1h 1m 50s)\n",
            "          acc: 0.99980, fpr: 0.00007, fnr: 0.00597, rec: 0.99403, prc: 0.99660, f1: 0.99531, f1_macro: 0.99761\n",
            "epoch: 14, passed number of graphs: 672, train running loss: 0.00116 (passed time: 1h 2m 23s)\n",
            "          acc: 0.99946, fpr: 0.00037, fnr: 0.00815, rec: 0.99185, prc: 0.98321, f1: 0.98751, f1_macro: 0.99362\n",
            "epoch: 14, passed number of graphs: 768, train running loss: 0.00124 (passed time: 1h 2m 55s)\n",
            "          acc: 0.99977, fpr: 0.00000, fnr: 0.01044, rec: 0.98956, prc: 0.99984, f1: 0.99467, f1_macro: 0.99728\n",
            "Validation --- epoch: 14, loss: 0.00165\n",
            "          acc: 0.99973, prc: 0.99701, fpr: 0.00007, f1_macro: 0.99651, fnr: 0.00945, f1: 0.99316, rec: 0.99055\n",
            "epoch: 15, passed number of graphs: 96, train running loss: 0.00093 (passed time: 1h 3m 37s)\n",
            "          acc: 0.99985, fpr: 0.00001, fnr: 0.00670, rec: 0.99330, prc: 0.99968, f1: 0.99648, f1_macro: 0.99820\n",
            "epoch: 15, passed number of graphs: 192, train running loss: 0.00104 (passed time: 1h 4m 10s)\n",
            "          acc: 0.99986, fpr: 0.00000, fnr: 0.00653, rec: 0.99347, prc: 1.00000, f1: 0.99672, f1_macro: 0.99833\n",
            "epoch: 15, passed number of graphs: 288, train running loss: 0.00099 (passed time: 1h 4m 42s)\n",
            "          acc: 0.99982, fpr: 0.00004, fnr: 0.00703, rec: 0.99297, prc: 0.99836, f1: 0.99566, f1_macro: 0.99778\n",
            "epoch: 15, passed number of graphs: 384, train running loss: 0.00123 (passed time: 1h 5m 15s)\n",
            "          acc: 0.99979, fpr: 0.00001, fnr: 0.00918, rec: 0.99082, prc: 0.99951, f1: 0.99515, f1_macro: 0.99752\n",
            "epoch: 15, passed number of graphs: 480, train running loss: 0.00115 (passed time: 1h 5m 48s)\n",
            "          acc: 0.99987, fpr: 0.00002, fnr: 0.00523, rec: 0.99477, prc: 0.99918, f1: 0.99697, f1_macro: 0.99845\n",
            "epoch: 15, passed number of graphs: 576, train running loss: 0.00111 (passed time: 1h 6m 20s)\n",
            "          acc: 0.99980, fpr: 0.00009, fnr: 0.00500, rec: 0.99500, prc: 0.99580, f1: 0.99540, f1_macro: 0.99765\n",
            "epoch: 15, passed number of graphs: 672, train running loss: 0.00112 (passed time: 1h 6m 53s)\n",
            "          acc: 0.99947, fpr: 0.00037, fnr: 0.00751, rec: 0.99249, prc: 0.98338, f1: 0.98791, f1_macro: 0.99382\n",
            "epoch: 15, passed number of graphs: 768, train running loss: 0.00118 (passed time: 1h 7m 25s)\n",
            "          acc: 0.99979, fpr: 0.00000, fnr: 0.00962, rec: 0.99038, prc: 0.99984, f1: 0.99508, f1_macro: 0.99749\n",
            "Validation --- epoch: 15, loss: 0.00161\n",
            "          acc: 0.99973, prc: 0.99722, fpr: 0.00007, f1_macro: 0.99657, fnr: 0.00947, f1: 0.99327, rec: 0.99053\n",
            "epoch: 16, passed number of graphs: 96, train running loss: 0.00154 (passed time: 1h 8m 7s)\n",
            "          acc: 0.99983, fpr: 0.00000, fnr: 0.00750, rec: 0.99250, prc: 0.99984, f1: 0.99616, f1_macro: 0.99804\n",
            "epoch: 16, passed number of graphs: 192, train running loss: 0.00176 (passed time: 1h 8m 40s)\n",
            "          acc: 0.99978, fpr: 0.00000, fnr: 0.01029, rec: 0.98971, prc: 1.00000, f1: 0.99483, f1_macro: 0.99736\n",
            "epoch: 16, passed number of graphs: 288, train running loss: 0.00160 (passed time: 1h 9m 12s)\n",
            "          acc: 0.99980, fpr: 0.00004, fnr: 0.00784, rec: 0.99216, prc: 0.99836, f1: 0.99525, f1_macro: 0.99757\n",
            "epoch: 16, passed number of graphs: 384, train running loss: 0.00146 (passed time: 1h 9m 45s)\n",
            "          acc: 0.99980, fpr: 0.00001, fnr: 0.00822, rec: 0.99178, prc: 0.99935, f1: 0.99555, f1_macro: 0.99773\n",
            "epoch: 16, passed number of graphs: 480, train running loss: 0.00135 (passed time: 1h 10m 18s)\n",
            "          acc: 0.99981, fpr: 0.00002, fnr: 0.00784, rec: 0.99216, prc: 0.99918, f1: 0.99566, f1_macro: 0.99778\n",
            "epoch: 16, passed number of graphs: 576, train running loss: 0.00128 (passed time: 1h 10m 50s)\n",
            "          acc: 0.99976, fpr: 0.00010, fnr: 0.00662, rec: 0.99338, prc: 0.99547, f1: 0.99443, f1_macro: 0.99715\n",
            "epoch: 16, passed number of graphs: 672, train running loss: 0.00132 (passed time: 1h 11m 23s)\n",
            "          acc: 0.99951, fpr: 0.00033, fnr: 0.00751, rec: 0.99249, prc: 0.98509, f1: 0.98878, f1_macro: 0.99426\n",
            "epoch: 16, passed number of graphs: 768, train running loss: 0.00134 (passed time: 1h 11m 55s)\n",
            "          acc: 0.99981, fpr: 0.00001, fnr: 0.00848, rec: 0.99152, prc: 0.99967, f1: 0.99558, f1_macro: 0.99774\n",
            "Validation --- epoch: 16, loss: 0.00162\n",
            "          acc: 0.99973, prc: 0.99712, fpr: 0.00007, f1_macro: 0.99655, fnr: 0.00941, f1: 0.99325, rec: 0.99059\n",
            "epoch: 17, passed number of graphs: 96, train running loss: 0.00090 (passed time: 1h 12m 37s)\n",
            "          acc: 0.99981, fpr: 0.00001, fnr: 0.00845, rec: 0.99155, prc: 0.99968, f1: 0.99560, f1_macro: 0.99775\n",
            "epoch: 17, passed number of graphs: 192, train running loss: 0.00107 (passed time: 1h 13m 10s)\n",
            "          acc: 0.99979, fpr: 0.00000, fnr: 0.00980, rec: 0.99020, prc: 1.00000, f1: 0.99508, f1_macro: 0.99748\n",
            "epoch: 17, passed number of graphs: 288, train running loss: 0.00102 (passed time: 1h 13m 42s)\n",
            "          acc: 0.99981, fpr: 0.00002, fnr: 0.00833, rec: 0.99167, prc: 0.99918, f1: 0.99541, f1_macro: 0.99765\n",
            "epoch: 17, passed number of graphs: 384, train running loss: 0.00106 (passed time: 1h 14m 15s)\n",
            "          acc: 0.99982, fpr: 0.00001, fnr: 0.00773, rec: 0.99227, prc: 0.99951, f1: 0.99588, f1_macro: 0.99789\n",
            "epoch: 17, passed number of graphs: 480, train running loss: 0.00105 (passed time: 1h 14m 48s)\n",
            "          acc: 0.99986, fpr: 0.00000, fnr: 0.00653, rec: 0.99347, prc: 1.00000, f1: 0.99672, f1_macro: 0.99833\n",
            "epoch: 17, passed number of graphs: 576, train running loss: 0.00103 (passed time: 1h 15m 20s)\n",
            "          acc: 0.99974, fpr: 0.00010, fnr: 0.00743, rec: 0.99257, prc: 0.99547, f1: 0.99402, f1_macro: 0.99694\n",
            "epoch: 17, passed number of graphs: 672, train running loss: 0.00106 (passed time: 1h 15m 53s)\n",
            "          acc: 0.99951, fpr: 0.00029, fnr: 0.00975, rec: 0.99025, prc: 0.98710, f1: 0.98867, f1_macro: 0.99421\n",
            "epoch: 17, passed number of graphs: 768, train running loss: 0.00108 (passed time: 1h 16m 25s)\n",
            "          acc: 0.99977, fpr: 0.00000, fnr: 0.01077, rec: 0.98923, prc: 0.99984, f1: 0.99451, f1_macro: 0.99719\n",
            "Validation --- epoch: 17, loss: 0.00162\n",
            "          acc: 0.99973, prc: 0.99710, fpr: 0.00007, f1_macro: 0.99654, fnr: 0.00942, f1: 0.99323, rec: 0.99058\n",
            "epoch: 18, passed number of graphs: 96, train running loss: 0.00115 (passed time: 1h 17m 7s)\n",
            "          acc: 0.99985, fpr: 0.00000, fnr: 0.00686, rec: 0.99314, prc: 0.99984, f1: 0.99648, f1_macro: 0.99820\n",
            "epoch: 18, passed number of graphs: 192, train running loss: 0.00119 (passed time: 1h 17m 40s)\n",
            "          acc: 0.99976, fpr: 0.00000, fnr: 0.01127, rec: 0.98873, prc: 1.00000, f1: 0.99433, f1_macro: 0.99711\n",
            "epoch: 18, passed number of graphs: 288, train running loss: 0.00112 (passed time: 1h 18m 12s)\n",
            "          acc: 0.99729, fpr: 0.00004, fnr: 0.12614, rec: 0.87386, prc: 0.99795, f1: 0.93179, f1_macro: 0.96520\n",
            "epoch: 18, passed number of graphs: 384, train running loss: 0.00117 (passed time: 1h 18m 45s)\n",
            "          acc: 0.99567, fpr: 0.00002, fnr: 0.19575, rec: 0.80425, prc: 0.99900, f1: 0.89111, f1_macro: 0.94445\n",
            "epoch: 18, passed number of graphs: 480, train running loss: 0.00112 (passed time: 1h 19m 18s)\n",
            "          acc: 0.99980, fpr: 0.00001, fnr: 0.00898, rec: 0.99102, prc: 0.99951, f1: 0.99524, f1_macro: 0.99757\n",
            "epoch: 18, passed number of graphs: 576, train running loss: 0.00119 (passed time: 1h 19m 50s)\n",
            "          acc: 0.99982, fpr: 0.00005, fnr: 0.00613, rec: 0.99387, prc: 0.99789, f1: 0.99588, f1_macro: 0.99789\n",
            "epoch: 18, passed number of graphs: 672, train running loss: 0.00116 (passed time: 1h 20m 23s)\n",
            "          acc: 0.99951, fpr: 0.00034, fnr: 0.00719, rec: 0.99281, prc: 0.98463, f1: 0.98870, f1_macro: 0.99423\n",
            "epoch: 18, passed number of graphs: 768, train running loss: 0.00119 (passed time: 1h 20m 56s)\n",
            "          acc: 0.99975, fpr: 0.00000, fnr: 0.01158, rec: 0.98842, prc: 0.99983, f1: 0.99409, f1_macro: 0.99698\n",
            "Validation --- epoch: 18, loss: 0.00162\n",
            "          acc: 0.99973, prc: 0.99714, fpr: 0.00007, f1_macro: 0.99653, fnr: 0.00954, f1: 0.99319, rec: 0.99046\n",
            "epoch: 19, passed number of graphs: 96, train running loss: 0.00091 (passed time: 1h 21m 37s)\n",
            "          acc: 0.99984, fpr: 0.00000, fnr: 0.00702, rec: 0.99298, prc: 0.99984, f1: 0.99640, f1_macro: 0.99816\n",
            "epoch: 19, passed number of graphs: 192, train running loss: 0.00100 (passed time: 1h 22m 10s)\n",
            "          acc: 0.99984, fpr: 0.00000, fnr: 0.00751, rec: 0.99249, prc: 1.00000, f1: 0.99623, f1_macro: 0.99807\n",
            "epoch: 19, passed number of graphs: 288, train running loss: 0.00103 (passed time: 1h 22m 42s)\n",
            "          acc: 0.99980, fpr: 0.00003, fnr: 0.00801, rec: 0.99199, prc: 0.99852, f1: 0.99525, f1_macro: 0.99757\n",
            "epoch: 19, passed number of graphs: 384, train running loss: 0.00121 (passed time: 1h 23m 15s)\n",
            "          acc: 0.99982, fpr: 0.00001, fnr: 0.00789, rec: 0.99211, prc: 0.99951, f1: 0.99580, f1_macro: 0.99785\n",
            "epoch: 19, passed number of graphs: 480, train running loss: 0.00114 (passed time: 1h 23m 48s)\n",
            "          acc: 0.99983, fpr: 0.00003, fnr: 0.00686, rec: 0.99314, prc: 0.99885, f1: 0.99599, f1_macro: 0.99795\n",
            "epoch: 19, passed number of graphs: 576, train running loss: 0.00111 (passed time: 1h 24m 20s)\n",
            "          acc: 0.99975, fpr: 0.00009, fnr: 0.00775, rec: 0.99225, prc: 0.99595, f1: 0.99410, f1_macro: 0.99698\n",
            "epoch: 19, passed number of graphs: 672, train running loss: 0.00121 (passed time: 1h 24m 53s)\n",
            "          acc: 0.99948, fpr: 0.00033, fnr: 0.00911, rec: 0.99089, prc: 0.98507, f1: 0.98797, f1_macro: 0.99385\n",
            "epoch: 19, passed number of graphs: 768, train running loss: 0.00124 (passed time: 1h 25m 26s)\n",
            "          acc: 0.99981, fpr: 0.00000, fnr: 0.00881, rec: 0.99119, prc: 0.99984, f1: 0.99549, f1_macro: 0.99770\n",
            "Validation --- epoch: 19, loss: 0.00163\n",
            "          acc: 0.99973, prc: 0.99700, fpr: 0.00007, f1_macro: 0.99652, fnr: 0.00941, f1: 0.99318, rec: 0.99059\n",
            "epoch: 20, passed number of graphs: 96, train running loss: 0.00104 (passed time: 1h 26m 7s)\n",
            "          acc: 0.99984, fpr: 0.00000, fnr: 0.00718, rec: 0.99282, prc: 0.99984, f1: 0.99632, f1_macro: 0.99812\n",
            "epoch: 20, passed number of graphs: 192, train running loss: 0.00119 (passed time: 1h 26m 40s)\n",
            "          acc: 0.99981, fpr: 0.00000, fnr: 0.00898, rec: 0.99102, prc: 1.00000, f1: 0.99549, f1_macro: 0.99770\n",
            "epoch: 20, passed number of graphs: 288, train running loss: 0.00141 (passed time: 1h 27m 12s)\n",
            "          acc: 0.99981, fpr: 0.00002, fnr: 0.00833, rec: 0.99167, prc: 0.99918, f1: 0.99541, f1_macro: 0.99765\n",
            "epoch: 20, passed number of graphs: 384, train running loss: 0.00136 (passed time: 1h 27m 45s)\n",
            "          acc: 0.99982, fpr: 0.00001, fnr: 0.00757, rec: 0.99243, prc: 0.99935, f1: 0.99588, f1_macro: 0.99789\n",
            "epoch: 20, passed number of graphs: 480, train running loss: 0.00146 (passed time: 1h 28m 18s)\n",
            "          acc: 0.99983, fpr: 0.00003, fnr: 0.00653, rec: 0.99347, prc: 0.99885, f1: 0.99615, f1_macro: 0.99803\n",
            "epoch: 20, passed number of graphs: 576, train running loss: 0.00144 (passed time: 1h 28m 50s)\n",
            "          acc: 0.99977, fpr: 0.00009, fnr: 0.00678, rec: 0.99322, prc: 0.99595, f1: 0.99458, f1_macro: 0.99723\n",
            "epoch: 20, passed number of graphs: 672, train running loss: 0.00140 (passed time: 1h 29m 23s)\n",
            "          acc: 0.99949, fpr: 0.00034, fnr: 0.00799, rec: 0.99201, prc: 0.98477, f1: 0.98838, f1_macro: 0.99406\n",
            "epoch: 20, passed number of graphs: 768, train running loss: 0.00137 (passed time: 1h 29m 56s)\n",
            "          acc: 0.99967, fpr: 0.00001, fnr: 0.01533, rec: 0.98467, prc: 0.99967, f1: 0.99211, f1_macro: 0.99597\n",
            "Validation --- epoch: 20, loss: 0.00163\n",
            "          acc: 0.99973, prc: 0.99703, fpr: 0.00007, f1_macro: 0.99652, fnr: 0.00944, f1: 0.99318, rec: 0.99056\n",
            "epoch: 21, passed number of graphs: 96, train running loss: 0.00099 (passed time: 1h 30m 37s)\n",
            "          acc: 0.99985, fpr: 0.00000, fnr: 0.00670, rec: 0.99330, prc: 0.99984, f1: 0.99656, f1_macro: 0.99824\n",
            "epoch: 21, passed number of graphs: 192, train running loss: 0.00102 (passed time: 1h 31m 10s)\n",
            "          acc: 0.99982, fpr: 0.00000, fnr: 0.00866, rec: 0.99134, prc: 1.00000, f1: 0.99565, f1_macro: 0.99778\n",
            "epoch: 21, passed number of graphs: 288, train running loss: 0.00111 (passed time: 1h 31m 43s)\n",
            "          acc: 0.99982, fpr: 0.00003, fnr: 0.00719, rec: 0.99281, prc: 0.99869, f1: 0.99574, f1_macro: 0.99782\n",
            "epoch: 21, passed number of graphs: 384, train running loss: 0.00122 (passed time: 1h 32m 15s)\n",
            "          acc: 0.99983, fpr: 0.00001, fnr: 0.00741, rec: 0.99259, prc: 0.99951, f1: 0.99604, f1_macro: 0.99798\n",
            "epoch: 21, passed number of graphs: 480, train running loss: 0.00124 (passed time: 1h 32m 48s)\n",
            "          acc: 0.99981, fpr: 0.00001, fnr: 0.00817, rec: 0.99183, prc: 0.99934, f1: 0.99557, f1_macro: 0.99774\n",
            "epoch: 21, passed number of graphs: 576, train running loss: 0.00129 (passed time: 1h 33m 21s)\n",
            "          acc: 0.99978, fpr: 0.00009, fnr: 0.00646, rec: 0.99354, prc: 0.99595, f1: 0.99475, f1_macro: 0.99732\n",
            "epoch: 21, passed number of graphs: 672, train running loss: 0.00139 (passed time: 1h 33m 53s)\n",
            "          acc: 0.99952, fpr: 0.00029, fnr: 0.00943, rec: 0.99057, prc: 0.98710, f1: 0.98883, f1_macro: 0.99429\n",
            "epoch: 21, passed number of graphs: 768, train running loss: 0.00147 (passed time: 1h 34m 26s)\n",
            "          acc: 0.99976, fpr: 0.00000, fnr: 0.01093, rec: 0.98907, prc: 0.99984, f1: 0.99442, f1_macro: 0.99715\n",
            "Validation --- epoch: 21, loss: 0.00163\n",
            "          acc: 0.99973, prc: 0.99712, fpr: 0.00007, f1_macro: 0.99652, fnr: 0.00952, f1: 0.99319, rec: 0.99048\n",
            "epoch: 22, passed number of graphs: 96, train running loss: 0.00100 (passed time: 1h 35m 8s)\n",
            "          acc: 0.99984, fpr: 0.00000, fnr: 0.00702, rec: 0.99298, prc: 0.99984, f1: 0.99640, f1_macro: 0.99816\n",
            "epoch: 22, passed number of graphs: 192, train running loss: 0.00104 (passed time: 1h 35m 40s)\n",
            "          acc: 0.99980, fpr: 0.00000, fnr: 0.00915, rec: 0.99085, prc: 1.00000, f1: 0.99541, f1_macro: 0.99765\n",
            "epoch: 22, passed number of graphs: 288, train running loss: 0.00101 (passed time: 1h 36m 13s)\n",
            "          acc: 0.99980, fpr: 0.00001, fnr: 0.00882, rec: 0.99118, prc: 0.99951, f1: 0.99532, f1_macro: 0.99761\n",
            "epoch: 22, passed number of graphs: 384, train running loss: 0.00105 (passed time: 1h 36m 45s)\n",
            "          acc: 0.99977, fpr: 0.00001, fnr: 0.00983, rec: 0.99017, prc: 0.99951, f1: 0.99482, f1_macro: 0.99735\n",
            "epoch: 22, passed number of graphs: 480, train running loss: 0.00102 (passed time: 1h 37m 18s)\n",
            "          acc: 0.99982, fpr: 0.00002, fnr: 0.00768, rec: 0.99232, prc: 0.99918, f1: 0.99574, f1_macro: 0.99782\n",
            "epoch: 22, passed number of graphs: 576, train running loss: 0.00102 (passed time: 1h 37m 51s)\n",
            "          acc: 0.99978, fpr: 0.00011, fnr: 0.00549, rec: 0.99451, prc: 0.99515, f1: 0.99483, f1_macro: 0.99736\n",
            "epoch: 22, passed number of graphs: 672, train running loss: 0.00104 (passed time: 1h 38m 23s)\n",
            "          acc: 0.99945, fpr: 0.00036, fnr: 0.00911, rec: 0.99089, prc: 0.98382, f1: 0.98734, f1_macro: 0.99353\n",
            "epoch: 22, passed number of graphs: 768, train running loss: 0.00108 (passed time: 1h 38m 56s)\n",
            "          acc: 0.99977, fpr: 0.00000, fnr: 0.01044, rec: 0.98956, prc: 0.99984, f1: 0.99467, f1_macro: 0.99728\n",
            "Validation --- epoch: 22, loss: 0.00161\n",
            "          acc: 0.99973, prc: 0.99709, fpr: 0.00007, f1_macro: 0.99657, fnr: 0.00931, f1: 0.99328, rec: 0.99069\n",
            "epoch: 23, passed number of graphs: 96, train running loss: 0.00099 (passed time: 1h 39m 38s)\n",
            "          acc: 0.99988, fpr: 0.00001, fnr: 0.00510, rec: 0.99490, prc: 0.99968, f1: 0.99728, f1_macro: 0.99861\n",
            "epoch: 23, passed number of graphs: 192, train running loss: 0.00117 (passed time: 1h 40m 10s)\n",
            "          acc: 0.99982, fpr: 0.00000, fnr: 0.00866, rec: 0.99134, prc: 1.00000, f1: 0.99565, f1_macro: 0.99778\n",
            "epoch: 23, passed number of graphs: 288, train running loss: 0.00122 (passed time: 1h 40m 43s)\n",
            "          acc: 0.99980, fpr: 0.00001, fnr: 0.00882, rec: 0.99118, prc: 0.99934, f1: 0.99524, f1_macro: 0.99757\n",
            "epoch: 23, passed number of graphs: 384, train running loss: 0.00136 (passed time: 1h 41m 16s)\n",
            "          acc: 0.99980, fpr: 0.00001, fnr: 0.00838, rec: 0.99162, prc: 0.99951, f1: 0.99555, f1_macro: 0.99773\n",
            "epoch: 23, passed number of graphs: 480, train running loss: 0.00128 (passed time: 1h 41m 48s)\n",
            "          acc: 0.99983, fpr: 0.00002, fnr: 0.00719, rec: 0.99281, prc: 0.99918, f1: 0.99599, f1_macro: 0.99795\n",
            "epoch: 23, passed number of graphs: 576, train running loss: 0.00120 (passed time: 1h 42m 21s)\n",
            "          acc: 0.99978, fpr: 0.00011, fnr: 0.00565, rec: 0.99435, prc: 0.99515, f1: 0.99475, f1_macro: 0.99732\n",
            "epoch: 23, passed number of graphs: 672, train running loss: 0.00131 (passed time: 1h 42m 54s)\n",
            "          acc: 0.99948, fpr: 0.00035, fnr: 0.00783, rec: 0.99217, prc: 0.98415, f1: 0.98814, f1_macro: 0.99394\n",
            "epoch: 23, passed number of graphs: 768, train running loss: 0.00130 (passed time: 1h 43m 27s)\n",
            "          acc: 0.99979, fpr: 0.00000, fnr: 0.00995, rec: 0.99005, prc: 0.99984, f1: 0.99492, f1_macro: 0.99740\n",
            "Validation --- epoch: 23, loss: 0.00162\n",
            "          acc: 0.99973, prc: 0.99709, fpr: 0.00007, f1_macro: 0.99655, fnr: 0.00940, f1: 0.99323, rec: 0.99060\n",
            "epoch: 24, passed number of graphs: 96, train running loss: 0.00099 (passed time: 1h 44m 8s)\n",
            "          acc: 0.99987, fpr: 0.00000, fnr: 0.00574, rec: 0.99426, prc: 0.99984, f1: 0.99704, f1_macro: 0.99849\n",
            "epoch: 24, passed number of graphs: 192, train running loss: 0.00120 (passed time: 1h 44m 41s)\n",
            "          acc: 0.99980, fpr: 0.00000, fnr: 0.00931, rec: 0.99069, prc: 1.00000, f1: 0.99532, f1_macro: 0.99761\n",
            "epoch: 24, passed number of graphs: 288, train running loss: 0.00123 (passed time: 1h 45m 14s)\n",
            "          acc: 0.99980, fpr: 0.00002, fnr: 0.00817, rec: 0.99183, prc: 0.99885, f1: 0.99533, f1_macro: 0.99761\n",
            "epoch: 24, passed number of graphs: 384, train running loss: 0.00128 (passed time: 1h 45m 46s)\n",
            "          acc: 0.99661, fpr: 0.00001, fnr: 0.15370, rec: 0.84630, prc: 0.99962, f1: 0.91659, f1_macro: 0.95743\n",
            "epoch: 24, passed number of graphs: 480, train running loss: 0.00126 (passed time: 1h 46m 19s)\n",
            "          acc: 0.99983, fpr: 0.00001, fnr: 0.00719, rec: 0.99281, prc: 0.99934, f1: 0.99607, f1_macro: 0.99799\n",
            "epoch: 24, passed number of graphs: 576, train running loss: 0.00120 (passed time: 1h 46m 52s)\n",
            "          acc: 0.99981, fpr: 0.00005, fnr: 0.00630, rec: 0.99370, prc: 0.99757, f1: 0.99563, f1_macro: 0.99777\n",
            "epoch: 24, passed number of graphs: 672, train running loss: 0.00118 (passed time: 1h 47m 24s)\n",
            "          acc: 0.99952, fpr: 0.00028, fnr: 0.00959, rec: 0.99041, prc: 0.98726, f1: 0.98883, f1_macro: 0.99429\n",
            "epoch: 24, passed number of graphs: 768, train running loss: 0.00120 (passed time: 1h 47m 57s)\n",
            "          acc: 0.99977, fpr: 0.00000, fnr: 0.01044, rec: 0.98956, prc: 0.99984, f1: 0.99467, f1_macro: 0.99728\n",
            "Validation --- epoch: 24, loss: 0.00161\n",
            "          acc: 0.99973, prc: 0.99702, fpr: 0.00007, f1_macro: 0.99660, fnr: 0.00913, f1: 0.99334, rec: 0.99087\n",
            "epoch: 25, passed number of graphs: 96, train running loss: 0.00115 (passed time: 1h 48m 38s)\n",
            "          acc: 0.99980, fpr: 0.00000, fnr: 0.00893, rec: 0.99107, prc: 0.99984, f1: 0.99543, f1_macro: 0.99767\n",
            "epoch: 25, passed number of graphs: 192, train running loss: 0.00110 (passed time: 1h 49m 11s)\n",
            "          acc: 0.99981, fpr: 0.00000, fnr: 0.00898, rec: 0.99102, prc: 1.00000, f1: 0.99549, f1_macro: 0.99770\n",
            "epoch: 25, passed number of graphs: 288, train running loss: 0.00106 (passed time: 1h 49m 44s)\n",
            "          acc: 0.99977, fpr: 0.00004, fnr: 0.00882, rec: 0.99118, prc: 0.99819, f1: 0.99467, f1_macro: 0.99728\n",
            "epoch: 25, passed number of graphs: 384, train running loss: 0.00110 (passed time: 1h 50m 16s)\n",
            "          acc: 0.99980, fpr: 0.00001, fnr: 0.00870, rec: 0.99130, prc: 0.99951, f1: 0.99539, f1_macro: 0.99764\n",
            "epoch: 25, passed number of graphs: 480, train running loss: 0.00111 (passed time: 1h 50m 49s)\n",
            "          acc: 0.99981, fpr: 0.00002, fnr: 0.00768, rec: 0.99232, prc: 0.99901, f1: 0.99566, f1_macro: 0.99778\n",
            "epoch: 25, passed number of graphs: 576, train running loss: 0.00114 (passed time: 1h 51m 22s)\n",
            "          acc: 0.99978, fpr: 0.00008, fnr: 0.00694, rec: 0.99306, prc: 0.99644, f1: 0.99474, f1_macro: 0.99732\n",
            "epoch: 25, passed number of graphs: 672, train running loss: 0.00113 (passed time: 1h 51m 54s)\n",
            "          acc: 0.99951, fpr: 0.00034, fnr: 0.00735, rec: 0.99265, prc: 0.98463, f1: 0.98862, f1_macro: 0.99418\n",
            "epoch: 25, passed number of graphs: 768, train running loss: 0.00113 (passed time: 1h 52m 27s)\n",
            "          acc: 0.99982, fpr: 0.00000, fnr: 0.00848, rec: 0.99152, prc: 0.99984, f1: 0.99566, f1_macro: 0.99778\n",
            "Validation --- epoch: 25, loss: 0.00162\n",
            "          acc: 0.99973, prc: 0.99724, fpr: 0.00007, f1_macro: 0.99653, fnr: 0.00962, f1: 0.99320, rec: 0.99038\n",
            "epoch: 26, passed number of graphs: 96, train running loss: 0.00098 (passed time: 1h 53m 9s)\n",
            "          acc: 0.99984, fpr: 0.00001, fnr: 0.00702, rec: 0.99298, prc: 0.99968, f1: 0.99632, f1_macro: 0.99812\n",
            "epoch: 26, passed number of graphs: 192, train running loss: 0.00136 (passed time: 1h 53m 41s)\n",
            "          acc: 0.99982, fpr: 0.00000, fnr: 0.00833, rec: 0.99167, prc: 1.00000, f1: 0.99582, f1_macro: 0.99786\n",
            "epoch: 26, passed number of graphs: 288, train running loss: 0.00138 (passed time: 1h 54m 14s)\n",
            "          acc: 0.99697, fpr: 0.00004, fnr: 0.14150, rec: 0.85850, prc: 0.99810, f1: 0.92305, f1_macro: 0.96075\n",
            "epoch: 26, passed number of graphs: 384, train running loss: 0.00129 (passed time: 1h 54m 47s)\n",
            "          acc: 0.99984, fpr: 0.00001, fnr: 0.00709, rec: 0.99291, prc: 0.99968, f1: 0.99628, f1_macro: 0.99810\n",
            "epoch: 26, passed number of graphs: 480, train running loss: 0.00122 (passed time: 1h 55m 19s)\n",
            "          acc: 0.99588, fpr: 0.00000, fnr: 0.19013, rec: 0.80987, prc: 0.99980, f1: 0.89487, f1_macro: 0.94638\n",
            "epoch: 26, passed number of graphs: 576, train running loss: 0.00115 (passed time: 1h 55m 52s)\n",
            "          acc: 0.99978, fpr: 0.00009, fnr: 0.00630, rec: 0.99370, prc: 0.99596, f1: 0.99483, f1_macro: 0.99736\n",
            "epoch: 26, passed number of graphs: 672, train running loss: 0.00116 (passed time: 1h 56m 24s)\n",
            "          acc: 0.99948, fpr: 0.00035, fnr: 0.00799, rec: 0.99201, prc: 0.98415, f1: 0.98806, f1_macro: 0.99390\n",
            "epoch: 26, passed number of graphs: 768, train running loss: 0.00117 (passed time: 1h 56m 57s)\n",
            "          acc: 0.99975, fpr: 0.00000, fnr: 0.01142, rec: 0.98858, prc: 0.99984, f1: 0.99418, f1_macro: 0.99703\n",
            "Validation --- epoch: 26, loss: 0.00161\n",
            "          acc: 0.99973, prc: 0.99724, fpr: 0.00006, f1_macro: 0.99655, fnr: 0.00954, f1: 0.99325, rec: 0.99046\n",
            "epoch: 27, passed number of graphs: 96, train running loss: 0.00129 (passed time: 1h 57m 39s)\n",
            "          acc: 0.99985, fpr: 0.00000, fnr: 0.00686, rec: 0.99314, prc: 0.99984, f1: 0.99648, f1_macro: 0.99820\n",
            "epoch: 27, passed number of graphs: 192, train running loss: 0.00134 (passed time: 1h 58m 12s)\n",
            "          acc: 0.99984, fpr: 0.00000, fnr: 0.00735, rec: 0.99265, prc: 1.00000, f1: 0.99631, f1_macro: 0.99812\n",
            "epoch: 27, passed number of graphs: 288, train running loss: 0.00131 (passed time: 1h 58m 44s)\n",
            "          acc: 0.99982, fpr: 0.00001, fnr: 0.00801, rec: 0.99199, prc: 0.99934, f1: 0.99565, f1_macro: 0.99778\n",
            "epoch: 27, passed number of graphs: 384, train running loss: 0.00124 (passed time: 1h 59m 17s)\n",
            "          acc: 0.99978, fpr: 0.00001, fnr: 0.00967, rec: 0.99033, prc: 0.99951, f1: 0.99490, f1_macro: 0.99739\n",
            "epoch: 27, passed number of graphs: 480, train running loss: 0.00118 (passed time: 1h 59m 49s)\n",
            "          acc: 0.99981, fpr: 0.00003, fnr: 0.00751, rec: 0.99249, prc: 0.99885, f1: 0.99566, f1_macro: 0.99778\n",
            "epoch: 27, passed number of graphs: 576, train running loss: 0.00117 (passed time: 2h 0m 22s)\n",
            "          acc: 0.99980, fpr: 0.00008, fnr: 0.00597, rec: 0.99403, prc: 0.99644, f1: 0.99523, f1_macro: 0.99756\n",
            "epoch: 27, passed number of graphs: 672, train running loss: 0.00114 (passed time: 2h 0m 55s)\n",
            "          acc: 0.99950, fpr: 0.00034, fnr: 0.00767, rec: 0.99233, prc: 0.98462, f1: 0.98846, f1_macro: 0.99410\n",
            "epoch: 27, passed number of graphs: 768, train running loss: 0.00121 (passed time: 2h 1m 27s)\n",
            "          acc: 0.99980, fpr: 0.00000, fnr: 0.00930, rec: 0.99070, prc: 0.99984, f1: 0.99525, f1_macro: 0.99757\n",
            "Validation --- epoch: 27, loss: 0.00162\n",
            "          acc: 0.99973, prc: 0.99707, fpr: 0.00007, f1_macro: 0.99654, fnr: 0.00940, f1: 0.99322, rec: 0.99060\n",
            "epoch: 28, passed number of graphs: 96, train running loss: 0.00115 (passed time: 2h 2m 9s)\n",
            "          acc: 0.99987, fpr: 0.00000, fnr: 0.00590, rec: 0.99410, prc: 0.99984, f1: 0.99696, f1_macro: 0.99845\n",
            "epoch: 28, passed number of graphs: 192, train running loss: 0.00145 (passed time: 2h 2m 41s)\n",
            "          acc: 0.99977, fpr: 0.00000, fnr: 0.01078, rec: 0.98922, prc: 1.00000, f1: 0.99458, f1_macro: 0.99723\n",
            "epoch: 28, passed number of graphs: 288, train running loss: 0.00130 (passed time: 2h 3m 14s)\n",
            "          acc: 0.99979, fpr: 0.00001, fnr: 0.00931, rec: 0.99069, prc: 0.99934, f1: 0.99499, f1_macro: 0.99744\n",
            "epoch: 28, passed number of graphs: 384, train running loss: 0.00142 (passed time: 2h 3m 47s)\n",
            "          acc: 0.99978, fpr: 0.00001, fnr: 0.00967, rec: 0.99033, prc: 0.99951, f1: 0.99490, f1_macro: 0.99739\n",
            "epoch: 28, passed number of graphs: 480, train running loss: 0.00134 (passed time: 2h 4m 19s)\n",
            "          acc: 0.99980, fpr: 0.00003, fnr: 0.00817, rec: 0.99183, prc: 0.99868, f1: 0.99525, f1_macro: 0.99757\n",
            "epoch: 28, passed number of graphs: 576, train running loss: 0.00126 (passed time: 2h 4m 52s)\n",
            "          acc: 0.99958, fpr: 0.00010, fnr: 0.01501, rec: 0.98499, prc: 0.99543, f1: 0.99018, f1_macro: 0.99498\n",
            "epoch: 28, passed number of graphs: 672, train running loss: 0.00129 (passed time: 2h 5m 25s)\n",
            "          acc: 0.99950, fpr: 0.00035, fnr: 0.00703, rec: 0.99297, prc: 0.98416, f1: 0.98855, f1_macro: 0.99415\n",
            "epoch: 28, passed number of graphs: 768, train running loss: 0.00129 (passed time: 2h 5m 57s)\n",
            "          acc: 0.99976, fpr: 0.00000, fnr: 0.01093, rec: 0.98907, prc: 0.99984, f1: 0.99442, f1_macro: 0.99715\n",
            "Validation --- epoch: 28, loss: 0.00162\n",
            "          acc: 0.99973, prc: 0.99722, fpr: 0.00007, f1_macro: 0.99655, fnr: 0.00954, f1: 0.99324, rec: 0.99046\n",
            "epoch: 29, passed number of graphs: 96, train running loss: 0.00122 (passed time: 2h 6m 39s)\n",
            "          acc: 0.99984, fpr: 0.00000, fnr: 0.00734, rec: 0.99266, prc: 0.99984, f1: 0.99624, f1_macro: 0.99808\n",
            "epoch: 29, passed number of graphs: 192, train running loss: 0.00115 (passed time: 2h 7m 12s)\n",
            "          acc: 0.99985, fpr: 0.00000, fnr: 0.00702, rec: 0.99298, prc: 1.00000, f1: 0.99648, f1_macro: 0.99820\n",
            "epoch: 29, passed number of graphs: 288, train running loss: 0.00120 (passed time: 2h 7m 44s)\n",
            "          acc: 0.99980, fpr: 0.00002, fnr: 0.00833, rec: 0.99167, prc: 0.99901, f1: 0.99533, f1_macro: 0.99761\n",
            "epoch: 29, passed number of graphs: 384, train running loss: 0.00113 (passed time: 2h 8m 17s)\n",
            "          acc: 0.99983, fpr: 0.00001, fnr: 0.00725, rec: 0.99275, prc: 0.99935, f1: 0.99604, f1_macro: 0.99798\n",
            "epoch: 29, passed number of graphs: 480, train running loss: 0.00108 (passed time: 2h 8m 50s)\n",
            "          acc: 0.99984, fpr: 0.00003, fnr: 0.00621, rec: 0.99379, prc: 0.99869, f1: 0.99623, f1_macro: 0.99808\n",
            "epoch: 29, passed number of graphs: 576, train running loss: 0.00110 (passed time: 2h 9m 22s)\n",
            "          acc: 0.99983, fpr: 0.00005, fnr: 0.00565, rec: 0.99435, prc: 0.99757, f1: 0.99596, f1_macro: 0.99793\n",
            "epoch: 29, passed number of graphs: 672, train running loss: 0.00113 (passed time: 2h 9m 55s)\n",
            "          acc: 0.99947, fpr: 0.00033, fnr: 0.00943, rec: 0.99057, prc: 0.98522, f1: 0.98789, f1_macro: 0.99381\n",
            "epoch: 29, passed number of graphs: 768, train running loss: 0.00117 (passed time: 2h 10m 28s)\n",
            "          acc: 0.99981, fpr: 0.00000, fnr: 0.00897, rec: 0.99103, prc: 0.99984, f1: 0.99541, f1_macro: 0.99766\n",
            "Validation --- epoch: 29, loss: 0.00164\n",
            "          acc: 0.99973, prc: 0.99698, fpr: 0.00007, f1_macro: 0.99651, fnr: 0.00944, f1: 0.99315, rec: 0.99056\n",
            "epoch: 30, passed number of graphs: 96, train running loss: 0.00094 (passed time: 2h 11m 9s)\n",
            "          acc: 0.99985, fpr: 0.00001, fnr: 0.00654, rec: 0.99346, prc: 0.99968, f1: 0.99656, f1_macro: 0.99824\n",
            "epoch: 30, passed number of graphs: 192, train running loss: 0.00098 (passed time: 2h 11m 42s)\n",
            "          acc: 0.99980, fpr: 0.00000, fnr: 0.00915, rec: 0.99085, prc: 1.00000, f1: 0.99541, f1_macro: 0.99765\n",
            "epoch: 30, passed number of graphs: 288, train running loss: 0.00106 (passed time: 2h 12m 14s)\n",
            "          acc: 0.99984, fpr: 0.00001, fnr: 0.00686, rec: 0.99314, prc: 0.99934, f1: 0.99623, f1_macro: 0.99807\n",
            "epoch: 30, passed number of graphs: 384, train running loss: 0.00100 (passed time: 2h 12m 47s)\n",
            "          acc: 0.99982, fpr: 0.00001, fnr: 0.00773, rec: 0.99227, prc: 0.99951, f1: 0.99588, f1_macro: 0.99789\n",
            "epoch: 30, passed number of graphs: 480, train running loss: 0.00108 (passed time: 2h 13m 20s)\n",
            "          acc: 0.99985, fpr: 0.00001, fnr: 0.00637, rec: 0.99363, prc: 0.99934, f1: 0.99648, f1_macro: 0.99820\n",
            "epoch: 30, passed number of graphs: 576, train running loss: 0.00113 (passed time: 2h 13m 52s)\n",
            "          acc: 0.99979, fpr: 0.00009, fnr: 0.00597, rec: 0.99403, prc: 0.99596, f1: 0.99499, f1_macro: 0.99744\n",
            "epoch: 30, passed number of graphs: 672, train running loss: 0.00116 (passed time: 2h 14m 25s)\n",
            "          acc: 0.99948, fpr: 0.00036, fnr: 0.00767, rec: 0.99233, prc: 0.98400, f1: 0.98815, f1_macro: 0.99394\n",
            "epoch: 30, passed number of graphs: 768, train running loss: 0.00116 (passed time: 2h 14m 57s)\n",
            "          acc: 0.99981, fpr: 0.00000, fnr: 0.00865, rec: 0.99135, prc: 0.99984, f1: 0.99558, f1_macro: 0.99774\n",
            "Validation --- epoch: 30, loss: 0.00161\n",
            "          acc: 0.99973, prc: 0.99716, fpr: 0.00007, f1_macro: 0.99655, fnr: 0.00945, f1: 0.99325, rec: 0.99055\n",
            "epoch: 31, passed number of graphs: 96, train running loss: 0.00128 (passed time: 2h 15m 39s)\n",
            "          acc: 0.99986, fpr: 0.00000, fnr: 0.00638, rec: 0.99362, prc: 0.99984, f1: 0.99672, f1_macro: 0.99832\n",
            "epoch: 31, passed number of graphs: 192, train running loss: 0.00132 (passed time: 2h 16m 12s)\n",
            "          acc: 0.99982, fpr: 0.00000, fnr: 0.00849, rec: 0.99151, prc: 1.00000, f1: 0.99574, f1_macro: 0.99782\n",
            "epoch: 31, passed number of graphs: 288, train running loss: 0.00120 (passed time: 2h 16m 45s)\n",
            "          acc: 0.99978, fpr: 0.00003, fnr: 0.00915, rec: 0.99085, prc: 0.99868, f1: 0.99475, f1_macro: 0.99732\n",
            "epoch: 31, passed number of graphs: 384, train running loss: 0.00123 (passed time: 2h 17m 17s)\n",
            "          acc: 0.99981, fpr: 0.00001, fnr: 0.00838, rec: 0.99162, prc: 0.99968, f1: 0.99563, f1_macro: 0.99777\n",
            "epoch: 31, passed number of graphs: 480, train running loss: 0.00117 (passed time: 2h 17m 50s)\n",
            "          acc: 0.99982, fpr: 0.00003, fnr: 0.00702, rec: 0.99298, prc: 0.99885, f1: 0.99590, f1_macro: 0.99791\n",
            "epoch: 31, passed number of graphs: 576, train running loss: 0.00112 (passed time: 2h 18m 23s)\n",
            "          acc: 0.99979, fpr: 0.00008, fnr: 0.00613, rec: 0.99387, prc: 0.99612, f1: 0.99499, f1_macro: 0.99744\n",
            "epoch: 31, passed number of graphs: 672, train running loss: 0.00111 (passed time: 2h 18m 55s)\n",
            "          acc: 0.99946, fpr: 0.00038, fnr: 0.00799, rec: 0.99201, prc: 0.98306, f1: 0.98751, f1_macro: 0.99362\n",
            "epoch: 31, passed number of graphs: 768, train running loss: 0.00115 (passed time: 2h 19m 28s)\n",
            "          acc: 0.99977, fpr: 0.00000, fnr: 0.01044, rec: 0.98956, prc: 0.99984, f1: 0.99467, f1_macro: 0.99728\n",
            "Validation --- epoch: 31, loss: 0.00162\n",
            "          acc: 0.99973, prc: 0.99713, fpr: 0.00007, f1_macro: 0.99655, fnr: 0.00945, f1: 0.99323, rec: 0.99055\n",
            "epoch: 32, passed number of graphs: 96, train running loss: 0.00135 (passed time: 2h 20m 9s)\n",
            "          acc: 0.99983, fpr: 0.00000, fnr: 0.00766, rec: 0.99234, prc: 0.99984, f1: 0.99608, f1_macro: 0.99800\n",
            "epoch: 32, passed number of graphs: 192, train running loss: 0.00129 (passed time: 2h 20m 42s)\n",
            "          acc: 0.99977, fpr: 0.00000, fnr: 0.01078, rec: 0.98922, prc: 1.00000, f1: 0.99458, f1_macro: 0.99723\n",
            "epoch: 32, passed number of graphs: 288, train running loss: 0.00133 (passed time: 2h 21m 15s)\n",
            "          acc: 0.99971, fpr: 0.00002, fnr: 0.01242, rec: 0.98758, prc: 0.99884, f1: 0.99318, f1_macro: 0.99652\n",
            "epoch: 32, passed number of graphs: 384, train running loss: 0.00137 (passed time: 2h 21m 47s)\n",
            "          acc: 0.99979, fpr: 0.00001, fnr: 0.00886, rec: 0.99114, prc: 0.99951, f1: 0.99531, f1_macro: 0.99760\n",
            "epoch: 32, passed number of graphs: 480, train running loss: 0.00128 (passed time: 2h 22m 20s)\n",
            "          acc: 0.99981, fpr: 0.00002, fnr: 0.00817, rec: 0.99183, prc: 0.99918, f1: 0.99549, f1_macro: 0.99770\n",
            "epoch: 32, passed number of graphs: 576, train running loss: 0.00121 (passed time: 2h 22m 52s)\n",
            "          acc: 0.99979, fpr: 0.00005, fnr: 0.00791, rec: 0.99209, prc: 0.99789, f1: 0.99498, f1_macro: 0.99744\n",
            "epoch: 32, passed number of graphs: 672, train running loss: 0.00121 (passed time: 2h 23m 25s)\n",
            "          acc: 0.99951, fpr: 0.00032, fnr: 0.00799, rec: 0.99201, prc: 0.98555, f1: 0.98877, f1_macro: 0.99426\n",
            "epoch: 32, passed number of graphs: 768, train running loss: 0.00120 (passed time: 2h 23m 57s)\n",
            "          acc: 0.99983, fpr: 0.00000, fnr: 0.00799, rec: 0.99201, prc: 0.99984, f1: 0.99591, f1_macro: 0.99791\n",
            "Validation --- epoch: 32, loss: 0.00163\n",
            "          acc: 0.99973, prc: 0.99707, fpr: 0.00007, f1_macro: 0.99654, fnr: 0.00941, f1: 0.99322, rec: 0.99059\n",
            "epoch: 33, passed number of graphs: 96, train running loss: 0.00125 (passed time: 2h 24m 39s)\n",
            "          acc: 0.99989, fpr: 0.00000, fnr: 0.00510, rec: 0.99490, prc: 0.99984, f1: 0.99736, f1_macro: 0.99865\n",
            "epoch: 33, passed number of graphs: 192, train running loss: 0.00113 (passed time: 2h 25m 12s)\n",
            "          acc: 0.99975, fpr: 0.00000, fnr: 0.01160, rec: 0.98840, prc: 1.00000, f1: 0.99417, f1_macro: 0.99702\n",
            "epoch: 33, passed number of graphs: 288, train running loss: 0.00108 (passed time: 2h 25m 44s)\n",
            "          acc: 0.99980, fpr: 0.00002, fnr: 0.00850, rec: 0.99150, prc: 0.99901, f1: 0.99524, f1_macro: 0.99757\n",
            "epoch: 33, passed number of graphs: 384, train running loss: 0.00109 (passed time: 2h 26m 17s)\n",
            "          acc: 0.99983, fpr: 0.00001, fnr: 0.00725, rec: 0.99275, prc: 0.99935, f1: 0.99604, f1_macro: 0.99798\n",
            "epoch: 33, passed number of graphs: 480, train running loss: 0.00117 (passed time: 2h 26m 50s)\n",
            "          acc: 0.99982, fpr: 0.00002, fnr: 0.00735, rec: 0.99265, prc: 0.99918, f1: 0.99590, f1_macro: 0.99791\n",
            "epoch: 33, passed number of graphs: 576, train running loss: 0.00119 (passed time: 2h 27m 22s)\n",
            "          acc: 0.99976, fpr: 0.00011, fnr: 0.00646, rec: 0.99354, prc: 0.99515, f1: 0.99435, f1_macro: 0.99711\n",
            "epoch: 33, passed number of graphs: 672, train running loss: 0.00116 (passed time: 2h 27m 55s)\n",
            "          acc: 0.99945, fpr: 0.00036, fnr: 0.00911, rec: 0.99089, prc: 0.98382, f1: 0.98734, f1_macro: 0.99353\n",
            "epoch: 33, passed number of graphs: 768, train running loss: 0.00116 (passed time: 2h 28m 28s)\n",
            "          acc: 0.99978, fpr: 0.00001, fnr: 0.00995, rec: 0.99005, prc: 0.99967, f1: 0.99484, f1_macro: 0.99736\n",
            "Validation --- epoch: 33, loss: 0.00162\n",
            "          acc: 0.99973, prc: 0.99704, fpr: 0.00007, f1_macro: 0.99656, fnr: 0.00930, f1: 0.99325, rec: 0.99070\n",
            "epoch: 34, passed number of graphs: 96, train running loss: 0.00139 (passed time: 2h 29m 9s)\n",
            "          acc: 0.99982, fpr: 0.00001, fnr: 0.00814, rec: 0.99186, prc: 0.99968, f1: 0.99576, f1_macro: 0.99783\n",
            "epoch: 34, passed number of graphs: 192, train running loss: 0.00122 (passed time: 2h 29m 42s)\n",
            "          acc: 0.99982, fpr: 0.00000, fnr: 0.00833, rec: 0.99167, prc: 1.00000, f1: 0.99582, f1_macro: 0.99786\n",
            "epoch: 34, passed number of graphs: 288, train running loss: 0.00111 (passed time: 2h 30m 15s)\n",
            "          acc: 0.99969, fpr: 0.00013, fnr: 0.00866, rec: 0.99134, prc: 0.99410, f1: 0.99272, f1_macro: 0.99628\n",
            "epoch: 34, passed number of graphs: 384, train running loss: 0.00106 (passed time: 2h 30m 47s)\n",
            "          acc: 0.99978, fpr: 0.00001, fnr: 0.00967, rec: 0.99033, prc: 0.99951, f1: 0.99490, f1_macro: 0.99739\n",
            "epoch: 34, passed number of graphs: 480, train running loss: 0.00102 (passed time: 2h 31m 20s)\n",
            "          acc: 0.99982, fpr: 0.00003, fnr: 0.00702, rec: 0.99298, prc: 0.99885, f1: 0.99590, f1_macro: 0.99791\n",
            "epoch: 34, passed number of graphs: 576, train running loss: 0.00101 (passed time: 2h 31m 53s)\n",
            "          acc: 0.99973, fpr: 0.00011, fnr: 0.00775, rec: 0.99225, prc: 0.99498, f1: 0.99362, f1_macro: 0.99674\n",
            "epoch: 34, passed number of graphs: 672, train running loss: 0.00101 (passed time: 2h 32m 25s)\n",
            "          acc: 0.99946, fpr: 0.00035, fnr: 0.00895, rec: 0.99105, prc: 0.98429, f1: 0.98766, f1_macro: 0.99369\n",
            "epoch: 34, passed number of graphs: 768, train running loss: 0.00110 (passed time: 2h 32m 58s)\n",
            "          acc: 0.99980, fpr: 0.00000, fnr: 0.00930, rec: 0.99070, prc: 1.00000, f1: 0.99533, f1_macro: 0.99761\n",
            "Validation --- epoch: 34, loss: 0.00161\n",
            "          acc: 0.99973, prc: 0.99712, fpr: 0.00007, f1_macro: 0.99659, fnr: 0.00927, f1: 0.99331, rec: 0.99073\n",
            "epoch: 35, passed number of graphs: 96, train running loss: 0.00147 (passed time: 2h 33m 39s)\n",
            "          acc: 0.99708, fpr: 0.00000, fnr: 0.13447, rec: 0.86553, prc: 0.99982, f1: 0.92784, f1_macro: 0.96317\n",
            "epoch: 35, passed number of graphs: 192, train running loss: 0.00124 (passed time: 2h 34m 12s)\n",
            "          acc: 0.99981, fpr: 0.00000, fnr: 0.00882, rec: 0.99118, prc: 1.00000, f1: 0.99557, f1_macro: 0.99774\n",
            "epoch: 35, passed number of graphs: 288, train running loss: 0.00119 (passed time: 2h 34m 45s)\n",
            "          acc: 0.99976, fpr: 0.00002, fnr: 0.01029, rec: 0.98971, prc: 0.99885, f1: 0.99425, f1_macro: 0.99707\n",
            "epoch: 35, passed number of graphs: 384, train running loss: 0.00121 (passed time: 2h 35m 17s)\n",
            "          acc: 0.99979, fpr: 0.00001, fnr: 0.00918, rec: 0.99082, prc: 0.99951, f1: 0.99515, f1_macro: 0.99752\n",
            "epoch: 35, passed number of graphs: 480, train running loss: 0.00115 (passed time: 2h 35m 50s)\n",
            "          acc: 0.99980, fpr: 0.00002, fnr: 0.00849, rec: 0.99151, prc: 0.99918, f1: 0.99533, f1_macro: 0.99761\n",
            "epoch: 35, passed number of graphs: 576, train running loss: 0.00116 (passed time: 2h 36m 23s)\n",
            "          acc: 0.99980, fpr: 0.00006, fnr: 0.00662, rec: 0.99338, prc: 0.99725, f1: 0.99531, f1_macro: 0.99760\n",
            "epoch: 35, passed number of graphs: 672, train running loss: 0.00118 (passed time: 2h 36m 55s)\n",
            "          acc: 0.99948, fpr: 0.00035, fnr: 0.00799, rec: 0.99201, prc: 0.98430, f1: 0.98814, f1_macro: 0.99394\n",
            "epoch: 35, passed number of graphs: 768, train running loss: 0.00117 (passed time: 2h 37m 28s)\n",
            "          acc: 0.99979, fpr: 0.00001, fnr: 0.00962, rec: 0.99038, prc: 0.99967, f1: 0.99500, f1_macro: 0.99745\n",
            "Validation --- epoch: 35, loss: 0.00160\n",
            "          acc: 0.99973, prc: 0.99708, fpr: 0.00007, f1_macro: 0.99661, fnr: 0.00917, f1: 0.99335, rec: 0.99083\n",
            "epoch: 36, passed number of graphs: 96, train running loss: 0.00127 (passed time: 2h 38m 10s)\n",
            "          acc: 0.99987, fpr: 0.00001, fnr: 0.00574, rec: 0.99426, prc: 0.99968, f1: 0.99696, f1_macro: 0.99845\n",
            "epoch: 36, passed number of graphs: 192, train running loss: 0.00110 (passed time: 2h 38m 42s)\n",
            "          acc: 0.99980, fpr: 0.00000, fnr: 0.00931, rec: 0.99069, prc: 0.99984, f1: 0.99524, f1_macro: 0.99757\n",
            "epoch: 36, passed number of graphs: 288, train running loss: 0.00116 (passed time: 2h 39m 15s)\n",
            "          acc: 0.99982, fpr: 0.00003, fnr: 0.00703, rec: 0.99297, prc: 0.99852, f1: 0.99574, f1_macro: 0.99782\n",
            "epoch: 36, passed number of graphs: 384, train running loss: 0.00118 (passed time: 2h 39m 48s)\n",
            "          acc: 0.99984, fpr: 0.00001, fnr: 0.00693, rec: 0.99307, prc: 0.99968, f1: 0.99636, f1_macro: 0.99814\n",
            "epoch: 36, passed number of graphs: 480, train running loss: 0.00117 (passed time: 2h 40m 20s)\n",
            "          acc: 0.99982, fpr: 0.00002, fnr: 0.00768, rec: 0.99232, prc: 0.99918, f1: 0.99574, f1_macro: 0.99782\n",
            "epoch: 36, passed number of graphs: 576, train running loss: 0.00125 (passed time: 2h 40m 53s)\n",
            "          acc: 0.99975, fpr: 0.00012, fnr: 0.00581, rec: 0.99419, prc: 0.99435, f1: 0.99427, f1_macro: 0.99707\n",
            "epoch: 36, passed number of graphs: 672, train running loss: 0.00123 (passed time: 2h 41m 26s)\n",
            "          acc: 0.99949, fpr: 0.00035, fnr: 0.00767, rec: 0.99233, prc: 0.98446, f1: 0.98838, f1_macro: 0.99406\n",
            "epoch: 36, passed number of graphs: 768, train running loss: 0.00129 (passed time: 2h 41m 58s)\n",
            "          acc: 0.99971, fpr: 0.00001, fnr: 0.01338, rec: 0.98662, prc: 0.99950, f1: 0.99302, f1_macro: 0.99644\n",
            "Validation --- epoch: 36, loss: 0.00163\n",
            "          acc: 0.99973, prc: 0.99704, fpr: 0.00007, f1_macro: 0.99651, fnr: 0.00947, f1: 0.99317, rec: 0.99053\n",
            "epoch: 37, passed number of graphs: 96, train running loss: 0.00097 (passed time: 2h 42m 40s)\n",
            "          acc: 0.99983, fpr: 0.00000, fnr: 0.00766, rec: 0.99234, prc: 0.99984, f1: 0.99608, f1_macro: 0.99800\n",
            "epoch: 37, passed number of graphs: 192, train running loss: 0.00117 (passed time: 2h 43m 13s)\n",
            "          acc: 0.99671, fpr: 0.00000, fnr: 0.15417, rec: 0.84583, prc: 1.00000, f1: 0.91647, f1_macro: 0.95740\n",
            "epoch: 37, passed number of graphs: 288, train running loss: 0.00115 (passed time: 2h 43m 45s)\n",
            "          acc: 0.99981, fpr: 0.00002, fnr: 0.00784, rec: 0.99216, prc: 0.99901, f1: 0.99557, f1_macro: 0.99774\n",
            "epoch: 37, passed number of graphs: 384, train running loss: 0.00118 (passed time: 2h 44m 18s)\n",
            "          acc: 0.99979, fpr: 0.00001, fnr: 0.00918, rec: 0.99082, prc: 0.99951, f1: 0.99515, f1_macro: 0.99752\n",
            "epoch: 37, passed number of graphs: 480, train running loss: 0.00118 (passed time: 2h 44m 51s)\n",
            "          acc: 0.99980, fpr: 0.00003, fnr: 0.00800, rec: 0.99200, prc: 0.99868, f1: 0.99533, f1_macro: 0.99761\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-7b17ca867fee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m# ========== train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Batch size: {batch_size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-14-7b17ca867fee>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, val_dataset, test_dataset, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-5545cffe0f7c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mconv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/models/rev_gnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fn_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inverse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/models/rev_gnn.py\u001b[0m in \u001b[0;36m_fn_apply\u001b[0;34m(self, args, fn, fn_inverse)\u001b[0m\n\u001b[1;32m    172\u001b[0m                 \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m                 \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m                 \u001b[0;34m*\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m             )\n\u001b[1;32m    176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/models/rev_gnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, fn, fn_inverse, num_bwd_passes, num_inputs, *args)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_requires_grad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/models/rev_gnn.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, x, edge_index, *args)\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0my_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0my_in\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m             \u001b[0mys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-47c4003d4b64>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, dropout_mask)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdropout_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdropout_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/conv/gin_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;31m# propagate_type: (x: OptPairTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mx_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Otherwise, run both functions in separation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 352\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mdecomposed_layers\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    353\u001b[0m                 \u001b[0muser_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__user_args__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m                 \u001b[0mdecomp_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muser_args\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'_j'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = torch.load(\"/content/saved_models/GIN_3: 0.9938360164396545.pt\")\n",
        "print('*' * 12 + f' best model obtained after epoch 4, '\n",
        "                    f'saved at {os.path.join(save_dir, save_name)} ' + '*' * 12)\n",
        "    \n",
        "predictor = PygModelPredictor(best_model)\n",
        "\n",
        "result_dict_avg, loss_avg = eval_predictor(test_ds, predictor)\n",
        "print(f'Testing --- loss: {loss_avg:.5f}')\n",
        "print(' ' * 10 + ', '.join(['{}: {:.5f}'.format(k, v) for k, v in result_dict_avg.items()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXW67xIFbnV1",
        "outputId": "d96202c4-6a27-4f01-b66e-48f0412fb032"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "************ best model obtained after epoch 11, saved at ./saved_models/GIN_model.pt ************\n",
            "Testing --- loss: 0.00137\n",
            "          acc: 0.99976, prc: 0.99670, fpr: 0.00008, f1_macro: 0.99708, fnr: 0.00763, f1: 0.99428, rec: 0.99237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rev_GIN_12Layer_MLP_3Layer_46Channels_2Group_19kParam_3_25GB"
      ],
      "metadata": {
        "id": "CJ0FLF9usjW9"
      }
    }
  ]
}